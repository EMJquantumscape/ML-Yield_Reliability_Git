{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the experiment code we want to look at.\n",
    "search = \"MLB000|MLB003|QSC022|MLB006|MLD023|MLD007|FCD|MLD012|MLD000|MLD025|MLD026\" #for all 6L baseline cells\n",
    "# search = \"MLD012|MLD016|MLD018|FCD00[0-5]|FCD009|MLB007\" #for 22L cells\n",
    "search = \"MLD023|MLB006\" #for 6L baseline builds with Cathy cells\n",
    "\n",
    "\n",
    "GroupBy = 'Experiment'  #Group cells by Experiment code (MLB006, MLD023, FCD00, etc) in screen and cycle plots\n",
    "#GroupBy = 'WorkWeek'  #Group cells by work week built in screen and cycle plots\n",
    "#GroupBy = 'Batch'   #Group cells by batches (MLB006AA, MLB006AB, MLB00AC, etc) in screen and cycle plots\n",
    "\n",
    "\n",
    "CellsToExclude = ['MLD023AB-PS00-01', 'MLD023AB-PS00-02', 'MLD023AB-PS00-05', 'QSC022AG-PS00-03', 'MLB006AP-PS00-04'] #Cells that should not be included in BOTH yield and reliability cycling analyses and plots\n",
    "CellsThatPassedScreen = ['MLD007AW-PS00-02', 'MLD007AX-PS00-01', 'MLD007AX-PS00-02', 'MLD007BA-PS00-01', 'MLD007BA-PS00-02', 'MLD007BA-PS00-04', 'MLB006AH-PS00-03',  'MLD023AC-PS00-02','MLD023AD-PS00-01','MLD023AD-PS00-02','MLD023AD-PS00-03', 'MLD023AD-PS00-04', 'MLD023AD-PS00-05'] # List of cells that did not fail screen despite datahub saying it did\n",
    "CellsThatFailedScreen = ['MLD023AF-PS00-03', 'MLD023AB-PS00-03'] # List of cells that should have failed screen despite datahub saying it didn't (i.e. \"soft-shorted\" during screening)\n",
    "\n",
    "builtby = \"7/01/2024\" #search for cells built on or after this date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Functions and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries and functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.utils import restricted_mean_survival_time\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from qsdc.client import Client\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "clrs = plotly.colors.DEFAULT_PLOTLY_COLORS\n",
    "qs_client = Client()\n",
    "\n",
    "#Remove warning messages\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "# Convert builtby to datetime\n",
    "builtby_date = pd.to_datetime(builtby, format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull from Datahub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull multilayer screen data\n",
    "MLScreenEach = qs_client.data_hub.get_dataset(dataset = 'MFG-80L-ML-SCREEN-CYCLE') ##electrical test data of unit cells for each cycle\n",
    "MLScreenSummary = qs_client.data_hub.get_dataset(dataset = 'MFG-80L-ML-SCREEN') ##electrical test data of unit cells that sumamrizes each screen test\n",
    "#Pull multilayer track cycle data\n",
    "MLTrackCycleEach = qs_client.data_hub.get_dataset(dataset = 'MFG-80L-TRACK-CYCLE-REL-CYCLE')\n",
    "MLTrackCycleSummary = qs_client.data_hub.get_dataset(dataset = 'MFG-80L-TRACK-CYCLE-REL')\n",
    "#Pull multilayer 1C cycle data\n",
    "MLslctCycleSummary = qs_client.data_hub.get_dataset(dataset = 'MFG-80L-ML-SLCT')\n",
    "MLslctCycleEach = qs_client.data_hub.get_dataset(dataset = 'MFG-80L-ML-SLCT-CYCLE')\n",
    "\n",
    "#Pull geneology/multilayer info of unit cells\n",
    "dmlg = qs_client.data_hub.get_dataset(dataset = 'MFG-80L-ML-PRODUCTION') ##multilayer info (ML_id)\n",
    "dmlg = dmlg.drop_duplicates(subset='US_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Master Spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a Master Spreadsheet for Screening data\n",
    "# Grab electrical metrics by consolidating individual cycles in screen\n",
    "def last_non_missing(series):\n",
    "    return series.dropna().iloc[-1] if not series.dropna().empty else None\n",
    "def minimum_non_missing(series):\n",
    "    return series.dropna().min() if not series.dropna().empty else None\n",
    "# Group by cell id and consolidate\n",
    "dfc_consolidated = (\n",
    "    MLScreenEach.groupby('MLT_id', as_index=False)\n",
    "    .agg({\n",
    "        'AMSDcCapacity': last_non_missing,\n",
    "        'DischargeCapacity': last_non_missing,\n",
    "        'dvdt':minimum_non_missing, \n",
    "        'MedDcASR': last_non_missing\n",
    "    })\n",
    ")\n",
    "dfc_consolidated = dfc_consolidated.rename(columns={\n",
    "    'AMSDcCapacity': 'CellSpecificDischargeCapacity',\n",
    "    'DischargeCapacity': 'CellCo3DischargeCapcity',\n",
    "    'dvdt': 'Celldvdt',\n",
    "    'MedDcASR': 'Cell1CDischargeASR'\n",
    "})\n",
    "MLScreenSummary = MLScreenSummary.merge(\n",
    "    dfc_consolidated,\n",
    "    left_on='MLT_id',\n",
    "    right_on='MLT_id',\n",
    "    how='inner'  # Use 'inner' to keep only matching rows; adjust to 'left' or 'outer' as needed\n",
    ")\n",
    "\n",
    "#Filter by what we are searching for\n",
    "filtered_MLScreenSummary = MLScreenSummary[MLScreenSummary['MLT_id'].str.contains(search, regex=True)]\n",
    "filtered_MLScreenEach = MLScreenEach[MLScreenEach['MLT_id'].str.contains(search, regex=True)]\n",
    "#Overwrite screen yield for cells that didn't really short\n",
    "columns_to_overwrite = ['stage1_yield', 'stage2_yield', 'stage3_yield', 'stage4_yield', 'stage5_yield'] # Specify columns to overwrite\n",
    "filtered_MLScreenSummary.loc[filtered_MLScreenSummary['MLT_id'].isin(CellsThatPassedScreen), columns_to_overwrite] = 1 # Overwrite the specified columns with 1 for matching rows\n",
    "filtered_MLScreenSummary.loc[filtered_MLScreenSummary['MLT_id'].isin(CellsThatPassedScreen), ['CycleFailure', 'AnyFailure']] = False # Overwrite the specified columns with 1 for matching rows\n",
    "# Suppose CellsThatFailedScreen is a list of strings\n",
    "filtered_MLScreenSummary.loc[filtered_MLScreenSummary['MLT_id'].isin(CellsThatFailedScreen), columns_to_overwrite] = 0 # Overwrite the specified columns with 1 for matching rows\n",
    "filtered_MLScreenSummary.loc[filtered_MLScreenSummary['MLT_id'].isin(CellsThatFailedScreen), ['CycleFailure', 'AnyFailure']] = True # Overwrite the specified columns with 1 for matching rows\n",
    "\n",
    "columns_to_overwrite2 = ['AnyFailure', 'CycleFailure'] # Specify columns to overwrite\n",
    "filtered_MLScreenSummary.loc[filtered_MLScreenSummary['MLT_id'].isin(CellsThatPassedScreen), columns_to_overwrite2] = False\n",
    "\n",
    "# Exclude cells\n",
    "MLScreenMaster = filtered_MLScreenSummary[~filtered_MLScreenSummary['MLT_id'].isin(CellsToExclude)] \n",
    "\n",
    "# Add additional columns that are typically used for grouping\n",
    "MLScreenMaster['Experiment']= MLScreenMaster['MLT_id'].str[:6]  #Group by experiment\n",
    "MLScreenMaster['Batch']= MLScreenMaster['MLT_id'].str[:8]  #Group by experiment\n",
    "MLScreenMaster['WorkWeek']= MLScreenMaster['TestCycleStart_week_first']  #Group by experiment\n",
    "\n",
    "\n",
    "# Group screen yield by:\n",
    "MLScreenMaster['Group']= MLScreenMaster[GroupBy]  #Group by experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a Master Spreadsheets for Cycling Data\n",
    "\n",
    "#Filter by what we are searching for\n",
    "MLTrackCycleSummary = MLTrackCycleSummary[MLTrackCycleSummary['sample_id'].str.contains(search, regex=True)]\n",
    "MLTrackCycleEach = MLTrackCycleEach[MLTrackCycleEach['sample_id'].str.contains(search, regex=True)]\n",
    "MLslctCycleSummary = MLslctCycleSummary[MLslctCycleSummary['MLT_id'].str.contains(search, regex=True)]\n",
    "MLslctCycleEach = MLslctCycleEach[MLslctCycleEach['MLT_id'].str.contains(search, regex=True)]\n",
    "\n",
    "# Exclude cells\n",
    "MLTrackCycleSummary = MLTrackCycleSummary[~MLTrackCycleSummary['sample_id'].isin(CellsToExclude)] \n",
    "MLTrackCycleEach = MLTrackCycleEach[~MLTrackCycleEach['sample_id'].isin(CellsToExclude)] \n",
    "MLslctCycleSummary = MLslctCycleSummary[~MLslctCycleSummary['MLT_id'].isin(CellsToExclude)] \n",
    "MLslctCycleEach = MLslctCycleEach[~MLslctCycleEach['MLT_id'].isin(CellsToExclude)] \n",
    "\n",
    "\n",
    "non_empty_failures = [cell for cell in CellsThatFailedScreen if cell.strip()]\n",
    "if non_empty_failures:\n",
    "    pattern = '|'.join(non_empty_failures)\n",
    "    MLTrackCycleSummary = MLTrackCycleSummary[~MLTrackCycleSummary['sample_id'].str.contains(pattern)]\n",
    "    MLTrackCycleEach = MLTrackCycleEach[~MLTrackCycleEach['sample_id'].str.contains(pattern)]\n",
    "    MLslctCycleSummary = MLslctCycleSummary[~MLslctCycleSummary['MLT_id'].str.contains(pattern)]\n",
    "    MLslctCycleEach = MLslctCycleEach[~MLslctCycleEach['MLT_id'].str.contains(pattern)]\n",
    "\n",
    "\n",
    "MLTrackCycleEach.loc[MLTrackCycleEach['MiscTestAnomaly'] == 1, ['dvdt_failure', 'min_track_cycle_voltage_failure', 'CapacityChargeFraction_failure'] ] = [0, 0, 0]\n",
    "\n",
    "# Add additional columns that are typically used for grouping\n",
    "MLTrackCycleEach['Experiment']= MLTrackCycleEach['sample_id'].str[:6]  #Group by experiment\n",
    "MLTrackCycleEach['Batch']= MLTrackCycleEach['sample_id'].str[:8]  #Group by experiment\n",
    "MLTrackCycleEach['WorkWeek']= MLTrackCycleEach['TestCycleStart_week_first']  #Group by experiment\n",
    "MLslctCycleEach['Experiment']= MLslctCycleEach['MLT_id'].str[:6]  #Group by experiment\n",
    "MLslctCycleEach['Batch']= MLslctCycleEach['MLT_id'].str[:8]  #Group by experiment\n",
    "MLslctCycleEach['WorkWeek']= MLslctCycleEach['TestCycleStart_week_first']  #Group by experiment\n",
    "\n",
    "MLTrackCycleSummary['Experiment']= MLTrackCycleSummary['sample_id'].str[:6]  #Group by experiment\n",
    "MLTrackCycleSummary['Batch']= MLTrackCycleSummary['sample_id'].str[:8]  #Group by experiment\n",
    "MLTrackCycleSummary['WorkWeek']= MLTrackCycleSummary['TestCycleStart_week_first']  #Group by experiment\n",
    "MLslctCycleSummary['Experiment']= MLslctCycleSummary['MLT_id'].str[:6]  #Group by experiment\n",
    "MLslctCycleSummary['Batch']= MLslctCycleSummary['MLT_id'].str[:8]  #Group by experiment\n",
    "MLslctCycleSummary['WorkWeek']= MLslctCycleSummary['TestCycleStart_week_first']  #Group by experiment\n",
    "\n",
    "# Group track cycles by:\n",
    "MLTrackCycleEach['Group']= MLTrackCycleEach[GroupBy]  #Group by experiment\n",
    "MLslctCycleEach['Group']= MLslctCycleEach[GroupBy]  #Group by experiment\n",
    "MLTrackCycleSummary['Group']= MLTrackCycleSummary[GroupBy]  #Group by experiment\n",
    "MLslctCycleSummary['Group']= MLslctCycleSummary[GroupBy]  #Group by experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tier Each ML Pouch\n",
    "#Pull geneology/multilayer info\n",
    "dmlg = dmlg.drop_duplicates(subset='US_id')\n",
    "CellsInML = MLScreenMaster.merge(dmlg, left_on='MLT_id', right_on='ML_id', how='left')\n",
    "CellsInML = CellsInML[['MLT_id', 'US_id']].rename(columns={'US_id': 'Cell ID'})\n",
    "\n",
    "#Pull cell metrology data from datahub, both standard/auto metrology and manual review\n",
    "dfctq = qs_client.data_hub.get_dataset(dataset = 'MFG-60L-UC-CTQ') ## standard metro\n",
    "\n",
    "dfctq_filtered = dfctq[dfctq['US_id'].isin(CellsInML['Cell ID'])]\n",
    "\n",
    "yielded_dfctq = dfctq_filtered[dfctq_filtered['unit_cell_test_yield'] == 1] #keep cells that yielded\n",
    "\n",
    "dfmr = qs_client.data_hub.get_dataset(dataset = 'MFG-60L-UC-MR') ## manual review\n",
    "dfmr_filtered = dfmr[dfmr['US_id'].isin(CellsInML['Cell ID'])]\n",
    "\n",
    "\n",
    "yielded_dfmr = dfmr_filtered[dfmr_filtered['unit_cell_test_yield'] == 1] #keep cells that yielded\n",
    "\n",
    "\n",
    "# First, merge the DataFrames on 'US_id' to align rows\n",
    "merged_df = yielded_dfctq.merge(yielded_dfmr[['US_id', 'edge_thickness_tier_us_mr', 'A1_anode_tier_top_us_mr', 'A1_anode_tier_bottom_us_mr',\n",
    "                                              'cathode_alignment_custom_model_tier_us_mr', 'median_contour_catholyte_pct_us_mr', 'disposition_mr', 'failure_modes_mr']], on='US_id', how='left')\n",
    "# Then, overwrite 'edge_thickness_tier_us' in 'filtered_dfctq' where 'edge_thickness_tier_us_mr' has a value\n",
    "merged_df['edge_thickness_tier_us'] = merged_df['edge_thickness_tier_us_mr'].combine_first(merged_df['edge_thickness_tier_us'])\n",
    "# Then, overwrite 'A1_anode_tier_top_us' in 'filtered_dfctq' where 'A1_anode_tier_top_us_mr' has a value\n",
    "merged_df['A1_anode_tier_top_us'] = merged_df['A1_anode_tier_top_us_mr'].combine_first(merged_df['A1_anode_tier_top_us'])\n",
    "# Then, overwrite 'A1_anode_tier_bottom_us' in 'filtered_dfctq' where 'A1_anode_tier_bottom_us_mr' has a value\n",
    "merged_df['A1_anode_tier_bottom_us'] = merged_df['A1_anode_tier_bottom_us_mr'].combine_first(merged_df['A1_anode_tier_bottom_us'])\n",
    "# Then, overwrite 'A1_anode_tier_bottom_us' in 'filtered_dfctq' where 'A1_anode_tier_bottom_us_mr' has a value\n",
    "merged_df['cathode_alignment_custom_model_tier_us'] = merged_df['cathode_alignment_custom_model_tier_us_mr'].combine_first(merged_df['cathode_alignment_custom_model_tier_us'])\n",
    "# Then, overwrite 'A1_anode_tier_bottom_us' in 'filtered_dfctq' where 'A1_anode_tier_bottom_us_mr' has a value\n",
    "merged_df['median_contour_catholyte_pct_us'] = merged_df['median_contour_catholyte_pct_us_mr'].combine_first(merged_df['median_contour_catholyte_pct_us'])\n",
    "# Then, overwrite 'disposition_us' in 'disposition_mr' has a value\n",
    "merged_df['disposition'] = merged_df['disposition_mr'].combine_first(merged_df['disposition'])\n",
    "# Then, overwrite 'disposition_us' in 'disposition_mr' has a value\n",
    "merged_df['failure_modes'] = merged_df['failure_modes_mr'].combine_first(merged_df['failure_modes'])\n",
    "# Drop the 'edge_thickness_tier_us_mr' column if you don't need it\n",
    "dfctq_updated = merged_df.drop(columns=['edge_thickness_tier_us_mr', 'A1_anode_tier_top_us_mr', 'A1_anode_tier_bottom_us_mr',\n",
    "                                              'cathode_alignment_custom_model_tier_us_mr', 'median_contour_catholyte_pct_us_mr', 'disposition_mr','failure_modes_mr' ])\n",
    "\n",
    "#Update Final Tier of Cells\n",
    "conditions = [\n",
    "    dfctq_updated['disposition'] == 'Tier 1',\n",
    "    dfctq_updated['disposition'] == 'Tier 2',\n",
    "    dfctq_updated['disposition'] == 'Fail',\n",
    "    dfctq_updated['disposition'] == 'Scrap',\n",
    "    dfctq_updated['disposition'] == 'Missing Data',\n",
    "]\n",
    "choices = ['1', '2', '3','Scrapped', 'TBD']\n",
    "dfctq_updated['Tier'] = np.select(conditions, choices)\n",
    "\n",
    "\n",
    "\n",
    "# Merge dfctq_updated['US_id', 'Tier'] with CellsInML based on 'US_id'\n",
    "CellsInML = CellsInML.merge(dfctq_updated[['US_id', 'Tier', 'center_normalized_0_5mm_eroded_rect_outside_median_us',]], \n",
    "                            left_on='Cell ID', \n",
    "                            right_on='US_id', \n",
    "                            how='left')\n",
    "\n",
    "\n",
    "# Assign the 'Tier' column to 'Cell Tier' and drop the extra 'US_id' column\n",
    "CellsInML['Cell Tier'] = CellsInML['Tier']\n",
    "CellsInML = CellsInML.drop(columns=['Tier', 'US_id'])\n",
    "\n",
    "# Group by \"samplename\" and find the max \"Cell Tier\" for each\n",
    "CellsInML['Cell Tier'] = pd.to_numeric(CellsInML['Cell Tier'], errors='coerce')\n",
    "FinalMLTier = CellsInML.groupby('MLT_id', as_index=False)['Cell Tier'].max()\n",
    "FinalMLThickness = CellsInML.groupby('MLT_id', as_index=False)['center_normalized_0_5mm_eroded_rect_outside_median_us'].max()\n",
    "\n",
    "# Rename columns as required\n",
    "FinalMLTier.columns = ['Multilayer', 'ML Tier']\n",
    "# Convert \"ML Tier\" to integer and format as \"Tier {max Cell Tier}\"\n",
    "# Conditionally update 'ML Tier'\n",
    "FinalMLTier['ML Tier'] = np.where(\n",
    "    FinalMLTier['ML Tier'].isna(), \n",
    "    np.nan,  # Keep NaN if it was originally NaN\n",
    "    \"Tier \" + FinalMLTier['ML Tier'].fillna(0).astype(int).astype(str)\n",
    ")\n",
    "\n",
    "# Merge df_master with FinalMLTier on \"samplename\" and \"Multilayer\"\n",
    "MLScreenMaster= MLScreenMaster.merge(FinalMLTier, left_on='MLT_id', right_on='Multilayer', how='left')\n",
    "# Merge df_master with FinalMLThickness on \"MLT_id\" and \"Multilayer\"\n",
    "MLScreenMaster = MLScreenMaster.merge(FinalMLThickness, left_on='MLT_id', right_on='MLT_id', how='left')\n",
    "\n",
    "# Update \"cell_tier_group\" with the values from \"ML Tier\"\n",
    "MLScreenMaster['cell_tier_group'] = MLScreenMaster['ML Tier']\n",
    "\n",
    "# Drop the extra \"Multilayer\" and \"ML Tier\" columns\n",
    "MLScreenMaster = MLScreenMaster.drop(columns=['Multilayer', 'ML Tier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Multilayer Screen Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Screen Yield\n",
    "finishedScreen = MLScreenMaster[MLScreenMaster[\"stage4_finished\"] == 1]  # Ensure it's an integer, not a string\n",
    "# finishedScreen = MLScreenMaster.copy()\n",
    "\n",
    "\n",
    "samples_to_plot = search\n",
    "grouping_to_plot = \"Group\"\n",
    "\n",
    "finishedScreen = finishedScreen[finishedScreen['ML_id'].str.contains(samples_to_plot)]\n",
    "grouped = finishedScreen.groupby(grouping_to_plot)\n",
    "\n",
    "\n",
    "# Calculate normalized bar values for each group\n",
    "bar_data = []\n",
    "group_labels = []\n",
    "for group, df_group in grouped:\n",
    "    total_rows = len(df_group)\n",
    "    stage1_count = df_group['stage1_yield'].sum()\n",
    "    stage2_count = df_group['stage2_yield'].sum()\n",
    "    stage3_count = df_group['stage3_yield'].sum()\n",
    "    stage5_count = df_group['stage4_yield'].sum()\n",
    "    \n",
    "    # Normalize the values to percentages\n",
    "    bar_values_percentage = [\n",
    "        (total_rows / total_rows) * 100,                          # Total rows (always 100%)\n",
    "        (stage1_count / total_rows) * 100,         # Excluding stage1\n",
    "        (stage2_count / total_rows) * 100,  # Excluding stage2\n",
    "        (stage3_count / total_rows) * 100,  # Excluding stage3\n",
    "        (stage5_count / total_rows) * 100                         # Stage5 (and Stage4) count\n",
    "    ]\n",
    "    \n",
    "    bar_data.append(bar_values_percentage)\n",
    "    group_labels.append(group)\n",
    "\n",
    "# Define bar labels\n",
    "bar_labels = ['Cells Built', 'Initial 1C Yield', 'Fast-Charge Yield', 'Final 1C Yield', 'C/3 Yield']\n",
    "# Create a new DataFrame for Plotly Express\n",
    "plot_data = pd.DataFrame(bar_data, columns=bar_labels, index=group_labels)\n",
    "# Reset index for x-axis labeling\n",
    "plot_data.reset_index(inplace=True)\n",
    "plot_data.rename(columns={'index': grouping_to_plot}, inplace=True)\n",
    "\n",
    "# Define colors for each bar\n",
    "colors = [\n",
    "    px.colors.qualitative.Plotly[2],  # Color for 'Total Rows'\n",
    "    px.colors.qualitative.Plotly[5],  # Color for 'Excluding Stage1'\n",
    "    px.colors.qualitative.Plotly[3],  # Color for 'Excluding Stage2'\n",
    "    px.colors.qualitative.Plotly[6],  # Color for 'Excluding Stage3'\n",
    "    px.colors.qualitative.Plotly[4]   # Color for 'Stage5 and Stage4 Count'\n",
    "]\n",
    "# Create the interactive bar chart with Plotly Express, specifying width, height, and custom font sizes\n",
    "fig = px.bar(\n",
    "    plot_data, \n",
    "    x=grouping_to_plot, \n",
    "    y=bar_labels, \n",
    "    title=\"Multilayer Screen Yield\", \n",
    "    labels={'value': 'Percentage (%)'}, \n",
    "    barmode='group', \n",
    "    color_discrete_sequence=colors,\n",
    "    # width=1200,  # Adjust width\n",
    "    # height=700   # Adjust height\n",
    ")\n",
    "\n",
    "# Update layout to increase font sizes\n",
    "fig.update_layout(\n",
    "    title=dict(font=dict(size=24)),          # Title font size\n",
    "    xaxis=dict(title=dict(font=dict(size=18)), tickfont=dict(size=16)),  # X-axis label and ticks\n",
    "    yaxis=dict(title=dict(font=dict(size=18)), tickfont=dict(size=16)),  # Y-axis label and ticks\n",
    "    legend=dict(font=dict(size=16)),         # Legend font size\n",
    ")\n",
    "\n",
    "\n",
    "# Compute total samples for each group\n",
    "plot_data[\"Total Samples\"] = plot_data[grouping_to_plot].apply(lambda g: len(finishedScreen[finishedScreen[grouping_to_plot] == g]))\n",
    "\n",
    "# Convert sample count to text for display\n",
    "build_count_text = [f\"<b>N={n}</b>\" for n in plot_data[\"Total Samples\"]]\n",
    "final_yield_text = [f\"<b>{y:.1f}%</b>\" for y in plot_data[\"C/3 Yield\"]]\n",
    "\n",
    "# Assign the text labels to the first and last bars in the grouped bars\n",
    "fig.data[0].text = build_count_text  # First bar (Cells Built)\n",
    "fig.data[-1].text = final_yield_text  # Last bar (C/3 Yield)\n",
    "\n",
    "# Ensure the text is displayed on the bars\n",
    "fig.update_traces(textposition=\"inside\", textfont_size=18)\n",
    "\n",
    "\n",
    "# add grey dotted line at 80% yield\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=-0.5,\n",
    "    x1=plot_data.shape[0] - 0.5,\n",
    "    y0=80,\n",
    "    y1=80,\n",
    "    line=dict(color=\"grey\", width=2, dash=\"dot\"),\n",
    "    )\n",
    "# Show the plot\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Cell Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify MLScreenMaster by removing non-yielded cells and cells we had to hardcode\n",
    "YieldedMLScreenMaster = MLScreenMaster.loc[MLScreenMaster['stage5_yield'] == 1]  # Keep cells that yielded for these plots\n",
    "YieldedMLScreenMaster = YieldedMLScreenMaster[~YieldedMLScreenMaster['MLT_id'].isin(CellsThatPassedScreen)]  # Filter out the DataFrame to exclude rows where 'MLT_id' is in CellsThatPassedScreen\n",
    "YieldedMLScreenMaster.reset_index(drop=True, inplace=True)  # Reset the index for the resulting DataFrame (optional)\n",
    "\n",
    "# Assuming YieldedMLScreenMaster is already loaded and has the necessary columns\n",
    "color_by = 'Group'  # Color differentiation by Group\n",
    "grouping = 'Group'\n",
    "\n",
    "# Add a new numeric column for x positions to shift points\n",
    "YieldedMLScreenMaster['group_numeric'] = pd.factorize(YieldedMLScreenMaster[grouping])[0]\n",
    "\n",
    "# Create a color dictionary for each unique value in Group\n",
    "color = dict(zip(YieldedMLScreenMaster[color_by].unique(), px.colors.qualitative.Plotly * 5))\n",
    "\n",
    "# Initialize subplot layout\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    horizontal_spacing=0.12,\n",
    "    vertical_spacing=0.1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=[\n",
    "        \"Specific Discharge Capacity\",\n",
    "        \"Cell Co3 Discharge Capacity\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Set a flag to ensure legend items are added only once\n",
    "legend_added = {key: False for key in YieldedMLScreenMaster[color_by].unique()}\n",
    "\n",
    "# Add traces for the first plot (CellSpecificDischargeCapacity)\n",
    "for label, group in YieldedMLScreenMaster.groupby(grouping):\n",
    "    for color_value, group_color in group.groupby(color_by):\n",
    "        # Add box plot\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group_color['group_numeric'],  # Use the numeric version of the grouping values\n",
    "                y=group_color[\"CellSpecificDischargeCapacity\"],\n",
    "                quartilemethod=\"linear\",\n",
    "                name=color_value,\n",
    "                text=group_color[\"sample_id\"] if \"sample_id\" in group_color.columns else None,\n",
    "                #showlegend=not legend_added[color_value],\n",
    "                showlegend=False,\n",
    "                fillcolor=color[color_value],\n",
    "                line=dict(color=\"black\"),\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # Add scatter points for individual data (with a slight shift to the left)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=group_color['group_numeric'] - 0.35,  # Shift numeric positions to the left\n",
    "                y=group_color[\"CellSpecificDischargeCapacity\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=color[color_value], size=6, symbol='circle'),\n",
    "                name=f\"{color_value} Points\",  # Separate legend for points\n",
    "                legendgroup=color_value,  # Group the legend for boxes and points\n",
    "                showlegend=False,  # Legend already handled for boxes\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        legend_added[color_value] = True\n",
    "\n",
    "# Reset the legend flags for the second plot\n",
    "legend_added = {key: False for key in YieldedMLScreenMaster[color_by].unique()}\n",
    "\n",
    "# Add traces for the second plot (CellCo3DischargeCapcity)\n",
    "for label, group in YieldedMLScreenMaster.groupby(grouping):\n",
    "    for color_value, group_color in group.groupby(color_by):\n",
    "        # Add box plot\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group_color['group_numeric'],  # Use the numeric version of the grouping values\n",
    "                y=group_color[\"CellCo3DischargeCapcity\"],\n",
    "                quartilemethod=\"linear\",\n",
    "                name=color_value,\n",
    "                text=group_color[\"sample_id\"] if \"sample_id\" in group_color.columns else None,\n",
    "                showlegend=not legend_added[color_value],\n",
    "                fillcolor=color[color_value],\n",
    "                line=dict(color=\"black\"),\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "        # Add scatter points for individual data (with a slight shift to the left)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=group_color['group_numeric'] - 0.35,  # Shift numeric positions to the left\n",
    "                y=group_color[\"CellCo3DischargeCapcity\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=color[color_value], size=6, symbol='circle'),\n",
    "                name=f\"{color_value} Points\",  # Separate legend for points\n",
    "                legendgroup=color_value,  # Group the legend for boxes and points\n",
    "                showlegend=False,  # Legend already handled for boxes\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        legend_added[color_value] = True\n",
    "\n",
    "# Update y-axes titles\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Discharge Capacity (mAh/g)\",\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Co3 Discharge Capacity (mAh)\",\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Update x-axes titles\n",
    "fig.update_xaxes(title_text=\"Group\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Group\", row=1, col=2)\n",
    "\n",
    "# Update x-axes ticks to show original grouping labels\n",
    "fig.update_xaxes(\n",
    "    tickmode='array',\n",
    "    tickvals=YieldedMLScreenMaster['group_numeric'].unique(),\n",
    "    ticktext=YieldedMLScreenMaster[grouping].unique(),\n",
    "    row=1, col=1,\n",
    "    ticks=\"outside\",  # Add ticks outside the plot\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    tickmode='array',\n",
    "    tickvals=YieldedMLScreenMaster['group_numeric'].unique(),\n",
    "    ticktext=YieldedMLScreenMaster[grouping].unique(),\n",
    "    row=1, col=2,\n",
    "    ticks=\"outside\",  # Add ticks outside the plot\n",
    ")\n",
    "\n",
    "# Update y-axes ticks to show original grouping labels\n",
    "fig.update_yaxes(\n",
    "    ticks=\"outside\",  # Add ticks outside the plot\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    ticks=\"outside\",  # Add ticks outside the plot\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add border to both subplots and adjust layout\n",
    "fig.update_layout(\n",
    "    title_text=\"\",\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    showlegend=True,\n",
    "    xaxis=dict(showgrid=True, zeroline=True, showline=True, linecolor='black', linewidth=2, mirror=True, ticks=\"outside\"),  # Border and ticks for the first subplot\n",
    "    yaxis=dict(showgrid=True, zeroline=True, showline=True, linecolor='black', linewidth=2, mirror=True, ticks=\"outside\"),  # Border and ticks for the first subplot\n",
    "    plot_bgcolor='white',  # Set plot background color to white\n",
    "    paper_bgcolor='white',  # Set paper background color to white\n",
    "    xaxis2=dict(showgrid=True, zeroline=True, showline=True, linecolor='black', linewidth=2, mirror=True, ticks=\"outside\"),  # Border and ticks for second subplot x-axis (all sides)\n",
    "    yaxis2=dict(showgrid=True, zeroline=True, showline=True, linecolor='black', linewidth=2, mirror=True, ticks=\"outside\"),  # Border and ticks for second subplot y-axis (all sides)\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show(renderer='browser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize subplot layout\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    horizontal_spacing=0.12,\n",
    "    vertical_spacing=0.1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=[\n",
    "        \"dV/dt\",\n",
    "        \"Discharge ASR\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Set a flag to ensure legend items are added only once\n",
    "legend_added = {key: False for key in YieldedMLScreenMaster[color_by].unique()}\n",
    "\n",
    "# Add traces for the first plot (Celldvdt)\n",
    "for label, group in YieldedMLScreenMaster.groupby(grouping):\n",
    "    for color_value, group_color in group.groupby(color_by):\n",
    "        # Add box plot\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group_color['group_numeric'],  # Use the numeric version of the grouping values\n",
    "                y=group_color[\"Celldvdt\"],\n",
    "                quartilemethod=\"linear\",\n",
    "                name=color_value,\n",
    "                text=group_color[\"sample_id\"] if \"sample_id\" in group_color.columns else None,\n",
    "                #showlegend=not legend_added[color_value],\n",
    "                showlegend=False,\n",
    "                fillcolor=color[color_value],\n",
    "                line=dict(color=\"black\"),\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # Add scatter points for individual data (with a slight shift to the left)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=group_color['group_numeric'] - 0.35,  # Shift numeric positions to the left\n",
    "                y=group_color[\"Celldvdt\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=color[color_value], size=6, symbol='circle'),\n",
    "                name=f\"{color_value} Points\",  # Separate legend for points\n",
    "                legendgroup=color_value,  # Group the legend for boxes and points\n",
    "                showlegend=False,  # Legend already handled for boxes\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        legend_added[color_value] = True\n",
    "\n",
    "# Reset the legend flags for the second plot\n",
    "legend_added = {key: False for key in YieldedMLScreenMaster[color_by].unique()}\n",
    "\n",
    "# Add traces for the second plot (Cell1CDischargeASR)\n",
    "for label, group in YieldedMLScreenMaster.groupby(grouping):\n",
    "    for color_value, group_color in group.groupby(color_by):\n",
    "        # Add box plot\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group_color['group_numeric'],  # Use the numeric version of the grouping values\n",
    "                y=group_color[\"Cell1CDischargeASR\"],\n",
    "                quartilemethod=\"linear\",\n",
    "                name=color_value,\n",
    "                text=group_color[\"sample_id\"] if \"sample_id\" in group_color.columns else None,\n",
    "                showlegend=not legend_added[color_value],\n",
    "                fillcolor=color[color_value],\n",
    "                line=dict(color=\"black\"),\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "        # Add scatter points for individual data (with a slight shift to the left)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=group_color['group_numeric'] - 0.35,  # Shift numeric positions to the left\n",
    "                y=group_color[\"Cell1CDischargeASR\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=color[color_value], size=6, symbol='circle'),\n",
    "                name=f\"{color_value} Points\",  # Separate legend for points\n",
    "                legendgroup=color_value,  # Group the legend for boxes and points\n",
    "                showlegend=False,  # Legend already handled for boxes\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        legend_added[color_value] = True\n",
    "\n",
    "# Update y-axes titles\n",
    "fig.update_yaxes(\n",
    "    title_text=\"dV/dt (ÂµV/s)\",\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"1C Discharge ASR (Ohm cm<sup>2</sup>)\",\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Update x-axes titles\n",
    "fig.update_xaxes(title_text=\"Group\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Group\", row=1, col=2)\n",
    "\n",
    "# Update x-axes ticks to show original grouping labels\n",
    "fig.update_xaxes(\n",
    "    tickmode='array',\n",
    "    tickvals=YieldedMLScreenMaster['group_numeric'].unique(),\n",
    "    ticktext=YieldedMLScreenMaster[grouping].unique(),\n",
    "    row=1, col=1,\n",
    "    ticks=\"outside\",  # Add ticks outside the plot\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    tickmode='array',\n",
    "    tickvals=YieldedMLScreenMaster['group_numeric'].unique(),\n",
    "    ticktext=YieldedMLScreenMaster[grouping].unique(),\n",
    "    row=1, col=2,\n",
    "    ticks=\"outside\",  # Add ticks outside the plot\n",
    ")\n",
    "\n",
    "# Update y-axes ticks to show original grouping labels\n",
    "fig.update_yaxes(\n",
    "    ticks=\"outside\",  # Add ticks outside the plot\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    ticks=\"outside\",  # Add ticks outside the plot\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add border to both subplots and adjust layout\n",
    "fig.update_layout(\n",
    "    title_text=\"\",\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    showlegend=True,\n",
    "    xaxis=dict(showgrid=True, zeroline=True, showline=True, linecolor='black', linewidth=2, mirror=True, ticks=\"outside\"),  # Border and ticks for the first subplot\n",
    "    yaxis=dict(showgrid=True, zeroline=True, showline=True, linecolor='black', linewidth=2, mirror=True, ticks=\"outside\"),  # Border and ticks for the first subplot\n",
    "    plot_bgcolor='white',  # Set plot background color to white\n",
    "    paper_bgcolor='white',  # Set paper background color to white\n",
    "    xaxis2=dict(showgrid=True, zeroline=True, showline=True, linecolor='black', linewidth=2, mirror=True, ticks=\"outside\"),  # Border and ticks for second subplot x-axis (all sides)\n",
    "    yaxis2=dict(showgrid=True, zeroline=True, showline=True, linecolor='black', linewidth=2, mirror=True, ticks=\"outside\"),  # Border and ticks for second subplot y-axis (all sides)\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show(renderer= 'browser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Vmin Cycling (Track and 1C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Vmin during track cycling\n",
    "# Order dataframe so it appears nicely in Vmin Reliability Plot\n",
    "MLTrackCycleEach = MLTrackCycleEach.sort_values(by=['sample_id', 'ReliabilityCycles'])\n",
    "\n",
    "# Create a scatter/line plot\n",
    "fig = px.scatter(\n",
    "    MLTrackCycleEach,\n",
    "    x='ReliabilityCycles',\n",
    "    y='min_track_cycle_voltage',\n",
    "    color='Group',\n",
    "    title=\"Minimum Cycle Voltage in Track Cycle Reliability\",\n",
    "    labels={'ReliabilityCycles': 'Cycle Count', 'min_track_cycle_voltage': 'Voltage (V)'},\n",
    "    hover_data={\"sample_id\": True} \n",
    ")\n",
    "\n",
    "# Update traces to include smaller points and lines\n",
    "fig.update_traces(mode='markers+lines', marker=dict(size=8), line=dict(width=2))\n",
    "\n",
    "# Customize axes\n",
    "fig.update_yaxes(\n",
    "    #range=[2.2, 3.1],\n",
    "    title='Voltage (V)',\n",
    "    tickfont=dict(size=22),\n",
    "    titlefont=dict(size=22),\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linewidth=2,\n",
    "    linecolor='grey'\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    range=[0, 100],\n",
    "    title='Cycle Number',\n",
    "    tickfont=dict(size=22),\n",
    "    titlefont=dict(size=22),\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linewidth=2,\n",
    "    linecolor='grey'\n",
    ")\n",
    "\n",
    "# Add a horizontal dotted line at 2.45V\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=0,\n",
    "    y0=2.45,\n",
    "    x1=100,\n",
    "    y1=2.45,\n",
    "    line=dict(color=\"black\", width=0.5, dash=\"dot\")\n",
    ")\n",
    "\n",
    "# Update layout for a clean appearance\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=600,\n",
    "    font=dict(size=20),\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer='browser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Vmin during 1C cycling\n",
    "# Order dataframe so it appears nicely in Vmin Reliability Plot\n",
    "MLslctCycleEach = MLslctCycleEach.sort_values(by=['MLT_id', 'ReliabilityCycles'])\n",
    "\n",
    "# Create a scatter/line plot\n",
    "fig = px.scatter(\n",
    "    MLslctCycleEach,\n",
    "    x='ReliabilityCycles',\n",
    "    y='DischargeCapacityRetention',\n",
    "    color='Group',\n",
    "    title=\"Discharge Capacity Retention of 1C Cycle Reliability\",\n",
    "    labels={'ReliabilityCycles': 'Cycle Count', 'CeilingRestVoltage': 'Voltage (V)'},\n",
    "    hover_data={\"MLT_id\": True} \n",
    ")\n",
    "\n",
    "# Update traces to include smaller points and lines\n",
    "fig.update_traces(mode='markers+lines', marker=dict(size=8), line=dict(width=2))\n",
    "\n",
    "# Customize axes\n",
    "fig.update_yaxes(\n",
    "    range=[0.8, 1.01],\n",
    "    title='Voltage (V)',\n",
    "    tickfont=dict(size=22),\n",
    "    titlefont=dict(size=22),\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linewidth=2,\n",
    "    linecolor='grey'\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    range=[0, 100],\n",
    "    title='Cycle Number',\n",
    "    tickfont=dict(size=22),\n",
    "    titlefont=dict(size=22),\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linewidth=2,\n",
    "    linecolor='grey'\n",
    ")\n",
    "\n",
    "# Add a horizontal dotted line at 2.45V\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=0,\n",
    "    y0=2.45,\n",
    "    x1=100,\n",
    "    y1=2.45,\n",
    "    line=dict(color=\"black\", width=0.5, dash=\"dot\")\n",
    ")\n",
    "\n",
    "# Update layout for a clean appearance\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=600,\n",
    "    font=dict(size=20),\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer='browser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Reliability Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lifelines\\utils\\__init__.py:320: IntegrationWarning:\n",
      "\n",
      "The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "\n",
      "c:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lifelines\\utils\\__init__.py:320: IntegrationWarning:\n",
      "\n",
      "The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Plot Track Cycle Survival Curve\n",
    "\n",
    "grouping_to_plot = 'Group'\n",
    "samples_to_plot = search\n",
    "samples_to_exclude_plot = None\n",
    "\n",
    "\n",
    "# Sort the DataFrame to prioritize rows based on the desired order\n",
    "MLTrackCycleEach = MLTrackCycleEach.sort_values(\n",
    "    by=['sample_id', 'track_cycle_count_cumulative', 'TestCycleStart_datetime'], \n",
    "    ascending=[True, False, False]\n",
    ")\n",
    "MLTrackCycleEachFiltered = MLTrackCycleEach[MLTrackCycleEach.sample_id.str.contains(samples_to_plot)]\n",
    "if samples_to_exclude_plot:\n",
    "    MLTrackCycleEachFiltered = MLTrackCycleEachFiltered [~MLTrackCycleEach.sample_id.str.contains(samples_to_exclude_plot)]\n",
    "# Merge df_master with FinalMLTier on \"samplename\" and \"Multilayer\"\n",
    "MLTrackCycleEachFiltered= MLTrackCycleEachFiltered.merge(FinalMLTier, left_on='sample_id', right_on='Multilayer', how='left')\n",
    "MLTrackCycleEachFiltered.drop(columns=['Multilayer'], inplace=True)\n",
    "# Merge df_master with FinalMLThickness on \"MLT_id\" and \"Multilayer\"\n",
    "MLTrackCycleEachFiltered = MLTrackCycleEachFiltered.merge(FinalMLThickness, left_on='sample_id', right_on='MLT_id', how='left')\n",
    "MLTrackCycleEachFiltered.drop(columns=['MLT_id'], inplace=True)\n",
    "### Filter rows by quality metrics\n",
    "# MLTrackCycleEachFiltered=MLTrackCycleEachFiltered[MLTrackCycleEachFiltered['center_normalized_0_5mm_eroded_rect_outside_median_us']<1.06]\n",
    "def select_cycle_count(group):\n",
    "    # Check if any of the failure conditions are met and track_cycle_count_cumulative > 0\n",
    "    failure_conditions = (group[['dvdt_failure', 'min_track_cycle_voltage_failure', 'CapacityChargeFraction_failure']] == 1).any(axis=1)\n",
    "    failure_rows = group[failure_conditions & (group[\"track_cycle_count_cumulative\"] > 0)]\n",
    "    \n",
    "    if not failure_rows.empty:\n",
    "        selected_row = failure_rows.nsmallest(1, \"track_cycle_count_cumulative\")  # Keep the first lowest non-zero failure\n",
    "        selected_row[\"Shorted\"] = True  # Mark as shorted\n",
    "    else:\n",
    "        selected_row = group.nlargest(1, \"track_cycle_count_cumulative\")  # Keep the highest if no failure is found\n",
    "        selected_row[\"Shorted\"] = False  # Mark as not shorted\n",
    "    \n",
    "    return selected_row\n",
    "MLLastTrackCycle = MLTrackCycleEachFiltered.groupby('sample_id', group_keys=False).apply(select_cycle_count)\n",
    "# Ensure TestCycleEnd_date is in datetime format\n",
    "MLLastTrackCycle['TestCycleEnd_date'] = pd.to_datetime(MLLastTrackCycle['TestCycleEnd_date'])\n",
    "# delete rows that have Nans for track_cycle_count_cumulative\n",
    "MLLastTrackCycle = MLLastTrackCycle.dropna(subset=['track_cycle_count_cumulative'])\n",
    "# Get today's date in the same format\n",
    "today_date = pd.to_datetime(datetime.today().date())\n",
    "# Update 'Shorted' to False if TestCycleEnd_date is today\n",
    "#MLLastTrackCycle.loc[MLLastTrackCycle['TestCycleEnd_date'] == today_date, 'Shorted'] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# delete rows that have Nans for track_cycle_count_cumulative\n",
    "MLTrackCycleSummary = MLTrackCycleSummary.dropna(subset=['track_cycle_count_cumulative'])\n",
    "#Keep samples that you want to plot\n",
    "MLTrackCycleSummary = MLTrackCycleSummary[MLTrackCycleSummary.sample_id.str.contains(samples_to_plot)]\n",
    "#exclude samples that you want to plot\n",
    "if samples_to_exclude_plot:\n",
    "    MLTrackCycleSummary = MLTrackCycleSummary [~MLTrackCycleSummary.sample_id.str.contains(samples_to_exclude_plot)]\n",
    "# Merge df_master with FinalMLTier on \"samplename\" and \"Multilayer\"\n",
    "MLTrackCycleSummary= MLTrackCycleSummary.merge(FinalMLTier, left_on='sample_id', right_on='Multilayer', how='left')\n",
    "MLTrackCycleSummary.drop(columns=['Multilayer'], inplace=True)\n",
    "# Merge df_master with FinalMLThickness on \"MLT_id\" and \"Multilayer\"\n",
    "MLTrackCycleSummary = MLTrackCycleSummary.merge(FinalMLThickness, left_on='sample_id', right_on='MLT_id', how='left')\n",
    "MLTrackCycleSummary.drop(columns=['MLT_id'], inplace=True)\n",
    "#Created 'Shorted' Column\n",
    "MLTrackCycleSummary['Shorted'] = MLTrackCycleSummary['CycleFailure']\n",
    "\n",
    "### Filter rows by quality metrics\n",
    "# MLTrackCycleSummary=MLTrackCycleSummary[MLTrackCycleSummary['center_normalized_0_5mm_eroded_rect_outside_median_us']<1.06]\n",
    "\n",
    "\n",
    "\n",
    "plotly_colors = [\n",
    "    # 'rgb(99, 110, 250)',    # Blue\n",
    "    'rgb(239, 85, 59)',     # Red-orange\n",
    "    'rgb(0, 204, 150)',     # Green\n",
    "    'rgb(171, 99, 250)',    # Purple\n",
    "    'rgb(255, 161, 90)',    # Orange\n",
    "    'rgb(25, 211, 243)',    # Cyan\n",
    "    'rgb(255, 102, 146)',   # Pink\n",
    "    'rgb(182, 232, 128)',   # Light green\n",
    "    'rgb(255, 151, 255)',   # Light pink\n",
    "    'rgb(254, 203, 82)'     # Yellow-orange\n",
    "]*10\n",
    "\n",
    "# Create figure\n",
    "fig = make_subplots()\n",
    "color_list = plotly_colors\n",
    "fill_color_list = ['rgba' + c[3:-1] + ', 0.15)' for c in color_list]\n",
    "i=0\n",
    "\n",
    "RMST_duration=60\n",
    "kmf1 = KaplanMeierFitter(alpha=0.05)  # this alpha is the Type I error rate\n",
    "results_df = pd.DataFrame(columns=['Condition', 'RMST', 'Variance', '95_CI'])\n",
    "range_x = 60\n",
    "\n",
    "# results_df = pd.DataFrame(columns=['Condition', 'RMST', 'Variance', '95_CI'])\n",
    "\n",
    "# df_rel_master_voltage_summary=pd.read_csv('Reliability_summary.csv')\n",
    "\n",
    "for Batch, grouped in MLTrackCycleSummary.groupby(grouping_to_plot):\n",
    "    \n",
    "    kmf1.fit(durations=grouped[\"track_cycle_count_cumulative\"], event_observed=grouped[\"Shorted\"])\n",
    "    df = kmf1.survival_function_.join(kmf1.confidence_interval_survival_function_)\n",
    "    df = df.join(\n",
    "        grouped.set_index(\"sample_id\")[[\"track_cycle_count_cumulative\", \"Shorted\"]]\n",
    "        .reset_index()\n",
    "        .groupby([\"track_cycle_count_cumulative\", \"Shorted\"])\n",
    "        .agg({\"sample_id\": \"<br>\\n\".join})\n",
    "        .reset_index()\n",
    "        .set_index(\"track_cycle_count_cumulative\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    df = df.fillna(value=True)\n",
    "    df[\"Shorted\"] = df[\"Shorted\"].apply(int)\n",
    "    df.loc[df.index==0, \"Shorted\" ] = 0\n",
    "    df['color']=color_list[i]\n",
    "\n",
    "\n",
    "    # Calculate RMST and variance\n",
    "    rmst, variance = restricted_mean_survival_time(kmf1, t=RMST_duration, return_variance=True)\n",
    "    \n",
    "    standard_error = np.sqrt(variance)\n",
    "    z_score = 1.96  # for 95% confidence interval\n",
    "\n",
    "    # Compute confidence intervals\n",
    "    ci = z_score * standard_error\n",
    "    \n",
    "\n",
    "    # Append results to the DataFrame\n",
    "    results_df = results_df.append({'Condition': Batch,\n",
    "                                    'RMST': rmst,\n",
    "                                    'Variance': variance,\n",
    "                                    '95_CI': ci}, ignore_index=True)\n",
    "    \n",
    "\n",
    "    # if six_layer:\n",
    "    #     if '6L' not in Batch:\n",
    "    #         df['KM_estimate']=df['KM_estimate']**3\n",
    "    #         df['KM_estimate_lower_0.95']=df['KM_estimate_lower_0.95']**3\n",
    "    #         df['KM_estimate_upper_0.95']=df['KM_estimate_upper_0.95']**3\n",
    "\n",
    "\n",
    "    trace1 = {\n",
    "        \"x\": df.index,\n",
    "        \"y\": df.KM_estimate,\n",
    "        \"line\": {\"shape\": \"hv\"},\n",
    "        \"mode\": \"lines\",\n",
    "        \"name\": \"value\",\n",
    "        \"type\": \"scatter\",\n",
    "    }\n",
    "\n",
    "    df=df.dropna(subset='Shorted')\n",
    "\n",
    "\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=df.KM_estimate * 100,\n",
    "            mode=\"markers+lines\",\n",
    "            line=dict(shape=\"hv\", width=3, color=color_list[i]),\n",
    "            marker=dict(color=df['color'], symbol='circle', size=7*(1-df['Shorted'])),\n",
    "            hovertext=df.sample_id,\n",
    "            name=f\"{Batch} (N={len(grouped)})\",\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=df[\"KM_estimate_upper_0.95\"] * 100,\n",
    "            mode=\"lines\",\n",
    "            line=dict(shape=\"hv\", width=0, color=color_list[i]),\n",
    "            name=\"\",  # f\"{Batch} UCI95%\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=df[\"KM_estimate_lower_0.95\"] * 100,\n",
    "            mode=\"lines\",\n",
    "            fill=\"tonexty\",\n",
    "            fillcolor=fill_color_list[i],\n",
    "            line=dict(shape=\"hv\", width=0, color=color_list[i]),\n",
    "            name=\"\",  # f\"{Batch} LCI95%\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"6L Reliability\",\n",
    "    xaxis=dict(title=\"Cycle Number\"),\n",
    "    yaxis=dict(title=\"Survival (%)\"),\n",
    "    font=dict(size=20),\n",
    "    legend={\"traceorder\": \"normal\"},\n",
    "    legend_title_text=grouping_to_plot,\n",
    "    # autosize=False,S\n",
    "    width=1075,\n",
    "    height=700,\n",
    "    # hide the legend\n",
    "    # showlegend=False,\n",
    ")\n",
    "\n",
    "# set background color to white\n",
    "fig.update_layout(plot_bgcolor='white')\n",
    "fig.update_yaxes(range=[0, 105], showline=True, linewidth=1, linecolor=\"black\", mirror=True)\n",
    "fig.update_xaxes(range=[0, 60], showline=True, linewidth=1, linecolor=\"black\", mirror=True)\n",
    "\n",
    "\n",
    "\n",
    "# add vertical grey dashed line to figure at 60 cycles\n",
    "fig.add_shape(\n",
    "        # Line Vertical\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0=60,\n",
    "            y0=0,\n",
    "            x1=60,\n",
    "            y1=105,\n",
    "            line=dict(\n",
    "                color=\"Grey\",\n",
    "                width=3,\n",
    "                dash=\"dash\",\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "go.Scatter(\n",
    "    x=[10],\n",
    "    y=[95],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(color=\"red\", symbol=\"circle\", size=20),\n",
    "    hovertext='95% Survival',\n",
    "    name=\"\",\n",
    "    # remove from legend\n",
    "    showlegend=False,\n",
    "),\n",
    "secondary_y=False,\n",
    ")\n",
    "# adding gate 2 22L target\n",
    "fig.add_trace(\n",
    "go.Scatter(\n",
    "    x=[60],\n",
    "    y=[95],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(color=\"blue\", symbol=\"circle\", size=20),\n",
    "    hovertext='95% Survival',\n",
    "    name=\"\",\n",
    "    # remove from legend\n",
    "    showlegend=False,\n",
    "),\n",
    "secondary_y=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.update_yaxes(range=[0, 105])\n",
    "fig.update_xaxes(range=[0, range_x])\n",
    "\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Initialize Kaplan-Meier fitter\n",
    "# kmf = KaplanMeierFitter(alpha=0.05)\n",
    "\n",
    "# # Offset for unique x-values to prevent overlapping indices\n",
    "# x_offset = 1e-6\n",
    "# #x_offset = 1\n",
    "\n",
    "# # Iterate over groups in MLTrackCycleSummary\n",
    "# for i, (group, group_data) in enumerate(MLTrackCycleSummary.groupby('Group')):\n",
    "#     # Prepare data for Kaplan-Meier fitting\n",
    "#     durations = group_data['track_cycle_count_cumulative'].to_numpy()\n",
    "#     event_observed = group_data['Shorted'].to_numpy()\n",
    "\n",
    "#     # Fit Kaplan-Meier model  \n",
    "#     kmf.fit(durations=durations, event_observed=event_observed)\n",
    "\n",
    "#     # Add survival curve trace\n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(\n",
    "#             x=kmf.survival_function_.index + (i * x_offset),  # Add offset to x-values\n",
    "#             y=kmf.survival_function_['KM_estimate'] * 100,\n",
    "#             mode=\"lines\",\n",
    "#             line=dict(shape=\"hv\", width=3, color=color_list[i]),\n",
    "#             name=f\"{group} (N={len(group_data)})\",\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     # Add confidence interval trace\n",
    "#     ci = kmf.confidence_interval_survival_function_\n",
    "    \n",
    "\n",
    "#     if not ci.empty:\n",
    "#         fig.add_trace(\n",
    "#             go.Scatter(\n",
    "#                 x=np.concatenate([ci.index, ci.index[::-1]]) + (i * x_offset),  # Offset x-values\n",
    "#                 y=np.concatenate([\n",
    "#                     ci['KM_estimate_upper_0.95'] * 100,\n",
    "#                     (ci['KM_estimate_lower_0.95'] * 100)[::-1]\n",
    "#                 ]),\n",
    "#                 mode=\"lines\",\n",
    "#                 fill=\"toself\",\n",
    "#                 fillcolor=fill_color_list[i],\n",
    "#                 line=dict(color='rgba(255,255,255,0)'),\n",
    "#                 showlegend=False,\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     # Add markers for hover labels\n",
    "#     predicted = kmf.predict(durations)\n",
    "#     survival_probabilities = np.array(predicted) if isinstance(predicted, (np.ndarray, pd.Series)) else np.array([predicted])\n",
    "\n",
    "#     customdata = np.stack(\n",
    "#         [\n",
    "#             group_data['sample_id'].to_numpy(),  # Sample ID\n",
    "#             group_data['ReliabilityCycles'].to_numpy(),  # Reliability cycles\n",
    "#             survival_probabilities * 100  # Survival percentage\n",
    "#         ],\n",
    "#         axis=-1\n",
    "#     )\n",
    "\n",
    "#     # Add marker trace for hover\n",
    "#     fig.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=durations + (i * x_offset),  # Add offset to x-values\n",
    "#         y=survival_probabilities * 100,\n",
    "#         mode=\"markers\",\n",
    "#         marker=dict(size=8, symbol=\"circle\", color=color_list[i]),\n",
    "#         customdata=customdata,\n",
    "#         hovertemplate=(\n",
    "#             \"<b>Sample ID:</b> %{customdata[0]}<br>\"\n",
    "#             \"<b>Reliability Cycles:</b> %{customdata[1]}<br>\"\n",
    "#             \"<b>Survival %:</b> %{customdata[2]:.2f}%\"\n",
    "#         ),\n",
    "#         hoverinfo=\"x+y+name+text\",  # Specify exactly what to show in the hover\n",
    "#         name=f\"{group} Markers\",  # Unique name for each group\n",
    "#         showlegend=False,  # Prevent marker legends from cluttering\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Finalize layout\n",
    "# fig.update_layout(\n",
    "#     title=\"Track Cycle Survival Plot by Group\",\n",
    "#     xaxis_title=\"Cycle Count\",\n",
    "#     yaxis_title=\"Survival Probability (%)\",\n",
    "#     legend_title=\"Groups\",\n",
    "#     font=dict(size=14),\n",
    "#     plot_bgcolor=\"white\",\n",
    "#     width=900,\n",
    "#     height=600\n",
    "# )\n",
    "\n",
    "# fig.add_shape(\n",
    "#             # Line Vertical\n",
    "#             dict(\n",
    "#                 type=\"line\",\n",
    "#                 x0=60,\n",
    "#                 y0=0,\n",
    "#                 x1=60,\n",
    "#                 y1=105,\n",
    "#                 line=dict(\n",
    "#                     color=\"Grey\",\n",
    "#                     width=3,\n",
    "#                     dash=\"dash\",\n",
    "#                 ),\n",
    "#             )\n",
    "#         )\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=[10],\n",
    "#         y=[95],\n",
    "#         mode=\"markers\",\n",
    "#         marker=dict(color=\"red\", symbol=\"circle\", size=20),\n",
    "#         hovertext='95% Survival',\n",
    "#         name=\"\",\n",
    "#         # remove from legend\n",
    "#         showlegend=False,\n",
    "#     ),\n",
    "#     secondary_y=False,\n",
    "#     )\n",
    "#     # adding gate 2 22L target\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=[60],\n",
    "#         y=[95],\n",
    "#         mode=\"markers\",\n",
    "#         marker=dict(color=\"blue\", symbol=\"circle\", size=20),\n",
    "#         hovertext='95% Survival',\n",
    "#         name=\"\",\n",
    "#         # remove from legend\n",
    "#         showlegend=False,\n",
    "#     ),\n",
    "#     secondary_y=False,\n",
    "#     )\n",
    "\n",
    "# fig.update_yaxes(range=[0, 105], showline=True, linewidth=1, linecolor=\"black\", mirror=True)\n",
    "# fig.update_xaxes(range=[0, 150], showline=True, linewidth=1, linecolor=\"black\", mirror=True)\n",
    "\n",
    "# fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 1C Cycle Survival Curve\n",
    "# Sort the DataFrame to prioritize rows based on the desired order\n",
    "MLslctCycleEach = MLslctCycleEach.sort_values(\n",
    "    by=['MLT_id', 'ReliabilityCycles', 'TestCycleStart_datetime'], \n",
    "    ascending=[True, False, False]\n",
    ")\n",
    "\n",
    "def select_cycle_count(group):\n",
    "    # Check if any of the failure conditions are met and track_cycle_count_cumulative > 0\n",
    "    failure_conditions = (group[['dvdt_failure', 'CapacityChargeFraction_failure']] == 1).any(axis=1)\n",
    "    failure_rows = group[failure_conditions & (group[\"ReliabilityCycles\"] > 0)]\n",
    "    \n",
    "    if not failure_rows.empty:\n",
    "        selected_row = failure_rows.nsmallest(1, \"ReliabilityCycles\")  # Keep the first lowest non-zero failure\n",
    "        selected_row[\"Shorted\"] = True  # Mark as shorted\n",
    "    else:\n",
    "        selected_row = group.nlargest(1, \"ReliabilityCycles\")  # Keep the highest if no failure is found\n",
    "        selected_row[\"Shorted\"] = False  # Mark as not shorted\n",
    "    \n",
    "    return selected_row\n",
    "\n",
    "MLLastslctCycle = MLslctCycleEach.groupby('MLT_id', group_keys=False).apply(select_cycle_count)\n",
    "\n",
    "# Ensure TestCycleEnd_date is in datetime format\n",
    "MLLastslctCycle['TestCycleEnd_date'] = pd.to_datetime(MLLastslctCycle['TestCycleEnd_date'])\n",
    "\n",
    "\n",
    "\n",
    "##Determine which cells in MLTrackCycleSummary shorted\n",
    "MLslctCycleSummary['Shorted'] = MLslctCycleSummary['CycleFailure']\n",
    "\n",
    "\n",
    "# Get today's date in the same format\n",
    "today_date = pd.to_datetime(datetime.today().date())\n",
    "\n",
    "# Update 'Shorted' to False if TestCycleEnd_date is today\n",
    "#MLLastTrackCycle.loc[MLLastTrackCycle['TestCycleEnd_date'] == today_date, 'Shorted'] = False\n",
    "\n",
    "\n",
    "plotly_colors = [\n",
    "    # 'rgb(99, 110, 250)',    # Blue\n",
    "    'rgb(239, 85, 59)',     # Red-orange\n",
    "    'rgb(0, 204, 150)',     # Green\n",
    "    'rgb(171, 99, 250)',    # Purple\n",
    "    'rgb(255, 161, 90)',    # Orange\n",
    "    'rgb(25, 211, 243)',    # Cyan\n",
    "    'rgb(255, 102, 146)',   # Pink\n",
    "    'rgb(182, 232, 128)',   # Light green\n",
    "    'rgb(255, 151, 255)',   # Light pink\n",
    "    'rgb(254, 203, 82)'     # Yellow-orange\n",
    "]*10\n",
    "\n",
    "# Create figure\n",
    "fig = make_subplots()\n",
    "color_list = plotly_colors\n",
    "fill_color_list = ['rgba' + c[3:-1] + ', 0.15)' for c in color_list]\n",
    "\n",
    "# Initialize Kaplan-Meier fitter\n",
    "kmf = KaplanMeierFitter(alpha=0.05)\n",
    "\n",
    "# Offset for unique x-values to prevent overlapping indices\n",
    "x_offset = 1e-6\n",
    "#x_offset = 1\n",
    "\n",
    "# Iterate over groups in MLslctCycleSummary\n",
    "for i, (group, group_data) in enumerate(MLslctCycleSummary.groupby('Group')):\n",
    "    # Prepare data for Kaplan-Meier fitting\n",
    "    durations = group_data['ReliabilityCycles'].to_numpy()\n",
    "    event_observed = group_data['Shorted'].to_numpy()\n",
    "\n",
    "    # Fit Kaplan-Meier model  \n",
    "    kmf.fit(durations=durations, event_observed=event_observed)\n",
    "\n",
    "    # Add survival curve trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=kmf.survival_function_.index + (i * x_offset),  # Add offset to x-values\n",
    "            y=kmf.survival_function_['KM_estimate'] * 100,\n",
    "            mode=\"lines\",\n",
    "            line=dict(shape=\"hv\", width=3, color=color_list[i]),\n",
    "            name=f\"{group} (N={len(group_data)})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add confidence interval trace\n",
    "    ci = kmf.confidence_interval_survival_function_\n",
    "      \n",
    "    if not ci.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.concatenate([ci.index, ci.index[::-1]]) + (i * x_offset),\n",
    "                y=np.concatenate([\n",
    "                    ci['KM_estimate_upper_0.95'] * 100,\n",
    "                    (ci['KM_estimate_lower_0.95'] * 100)[::-1]\n",
    "                ]),\n",
    "                mode=\"lines\",\n",
    "                fill=\"toself\",\n",
    "                fillcolor=fill_color_list[i],\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                showlegend=False,\n",
    "                hoverinfo=\"skip\"  # <- Prevents hover over CI\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add markers for hover labels\n",
    "    predicted = kmf.predict(durations)\n",
    "    survival_probabilities = np.array(predicted) if isinstance(predicted, (np.ndarray, pd.Series)) else np.array([predicted])\n",
    "\n",
    "    customdata = np.stack(\n",
    "        [\n",
    "            group_data['MLT_id'].to_numpy(),  # Sample ID\n",
    "            group_data['ReliabilityCycles'].to_numpy(),  # Reliability cycles\n",
    "            survival_probabilities * 100  # Survival percentage\n",
    "        ],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "    # Add marker trace for hover\n",
    "    fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=durations + (i * x_offset),  # Add offset to x-values\n",
    "        y=survival_probabilities * 100,\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=8, symbol=\"circle\", color=color_list[i]),\n",
    "        customdata=customdata,\n",
    "        hovertemplate=(\n",
    "            \"<b>Sample ID:</b> %{customdata[0]}<br>\"\n",
    "            \"<b>Reliability Cycles:</b> %{customdata[1]}<br>\"\n",
    "            \"<b>Survival %:</b> %{customdata[2]:.2f}%\"\n",
    "        ),\n",
    "        hoverinfo=\"x+y+name+text\",  # Specify exactly what to show in the hover\n",
    "        name=f\"{group} Markers\",  # Unique name for each group\n",
    "        showlegend=False,  # Prevent marker legends from cluttering\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Finalize layout\n",
    "fig.update_layout(\n",
    "    title=\"1C Cycle Survival Plot by Group\",\n",
    "    xaxis_title=\"Cycle Count\",\n",
    "    yaxis_title=\"Survival Probability (%)\",\n",
    "    legend_title=\"Groups\",\n",
    "    font=dict(size=14),\n",
    "    plot_bgcolor=\"white\",\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.add_shape(\n",
    "            # Line Vertical\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                x0=60,\n",
    "                y0=0,\n",
    "                x1=60,\n",
    "                y1=105,\n",
    "                line=dict(\n",
    "                    color=\"Grey\",\n",
    "                    width=3,\n",
    "                    dash=\"dash\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(\n",
    "#        x=[10],\n",
    "#        y=[95],\n",
    "#        mode=\"markers\",\n",
    "#        hovertext='95% Survival',\n",
    "#        name=\"\",\n",
    "#        # remove from legend\n",
    "#        showlegend=False,\n",
    "#    ),\n",
    "#    secondary_y=False,\n",
    "#    )\n",
    "    # adding gate 2 22L target\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(\n",
    "#        x=[60],\n",
    "#        y=[95],\n",
    "#        mode=\"markers\",\n",
    "#        marker=dict(color=\"blue\", symbol=\"circle\", size=20),\n",
    "#        hovertext='95% Survival',\n",
    "#        name=\"\",\n",
    "#        # remove from legend\n",
    "#        showlegend=False,\n",
    "#    ),\n",
    "#    secondary_y=False,\n",
    "#    )\n",
    "\n",
    "fig.update_yaxes(range=[0, 105], showline=True, linewidth=1, linecolor=\"black\", mirror=True)\n",
    "fig.update_xaxes(range=[0, 100], showline=True, linewidth=1, linecolor=\"black\", mirror=True)\n",
    "\n",
    "fig.show(renderer='browser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce ML Tracker Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'ML_TrackingResults.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#save the updated dataframe\u001b[39;00m\n\u001b[0;32m     51\u001b[0m Output_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mML_TrackingResults.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mdf_screening\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOutput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:2374\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2361\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2363\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2364\u001b[0m     df,\n\u001b[0;32m   2365\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2372\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2373\u001b[0m )\n\u001b[1;32m-> 2374\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2376\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\excel.py:944\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    940\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 944\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:205\u001b[0m, in \u001b[0;36mXlsxWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_book \u001b[38;5;241m=\u001b[39m Workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1313\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1310\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1311\u001b[0m )\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\EDM02\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'ML_TrackingResults.xlsx'"
     ]
    }
   ],
   "source": [
    "# Rename columns and assign to df_screening\n",
    "df_screening = MLScreenMaster[\n",
    "    ['MLT_id', 'cell_tier_group', 'CycleFailure', 'TestCycleStart_date', 'ElectricalTestTool', 'ElectricalTestChannel']\n",
    "].rename(\n",
    "    columns={\n",
    "        'MLT_id': 'MultilayerID',\n",
    "        'cell_tier_group': 'Tier',\n",
    "        'CycleFailure': 'ML Screen Yield',\n",
    "        'TestCycleStart_date': 'Build Date',\n",
    "        'ElectricalTestTool': 'Tool',\n",
    "        'ElectricalTestChannel': 'Channel'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Relabel 'false' to 'Pass' and 'true' to 'Failed'\n",
    "df_screening['ML Screen Yield'] = df_screening['ML Screen Yield'].replace({False: 'Pass', True: 'Fail'})\n",
    "\n",
    "\n",
    "# Merge 'ML___CycleSummary' into 'df_screening'\n",
    "df_screening = pd.merge(\n",
    "    df_screening,\n",
    "    MLTrackCycleSummary[['sample_id', 'ElectricalTestTool', 'ElectricalTestChannel', 'CycleFailure', 'ReliabilityCycles', 'Test_Version']],\n",
    "    left_on='MultilayerID',  # Column in 'df_screening'\n",
    "    right_on='sample_id',    # Column in 'MLLastTrackCycle'\n",
    "    how='left'               # Use 'left' join to keep all rows from 'df_screening'\n",
    ")\n",
    "# Overwrite 'Tool' and 'Channel' where 'ElectricalTestTool' and 'ElectricalTestChannel' have values\n",
    "df_screening['Tool'] = df_screening['ElectricalTestTool'].combine_first(df_screening['Tool'])\n",
    "df_screening['Channel'] = df_screening['ElectricalTestChannel'].combine_first(df_screening['Channel'])\n",
    "# Drop the additional columns no longer needed\n",
    "df_screening = df_screening.drop(columns=['ElectricalTestTool', 'ElectricalTestChannel', 'sample_id'])\n",
    "\n",
    "# Merge df_screening with MLslctCycleSummary based on matching MultilayerID and sample_id\n",
    "if not MLslctCycleSummary.empty:\n",
    "    df_screening.update(\n",
    "        df_screening.set_index('MultilayerID')\n",
    "        .combine_first(MLslctCycleSummary.set_index('ML_id'))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Rename 'CycleFailure' to 'Cycle Status'\n",
    "df_screening = df_screening.rename(columns={'CycleFailure': 'Cycle Status', 'Test_Version':'Cycling Test Version'})\n",
    "\n",
    "# Replace 'True' with 'Shorted' and 'False' with 'Live' in the 'Cycle Status' column\n",
    "df_screening['Cycle Status'] = df_screening['Cycle Status'].replace({True: 'Shorted', False: 'Live'})\n",
    "\n",
    "#save the updated dataframe\n",
    "Output_name = 'ML_TrackingResults.xlsx'\n",
    "df_screening.to_excel(Output_name, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
