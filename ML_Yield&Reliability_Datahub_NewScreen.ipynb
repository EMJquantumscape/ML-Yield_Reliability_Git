{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the experiment code we want to look at. Default:\n",
    "#search = \"APD256|MLB|MLD|QSC\"\n",
    "#search = \"APD253\"\n",
    "search = \"MLB003|MLB004|MLD015\"\n",
    "exclude = \"None\"\n",
    "builtby = \"7/01/2024\" #search for cells built on or after this date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Functions and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries and functions\n",
    "import genealogy_v2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.utils import restricted_mean_survival_time\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "from qsdc.client import Client\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "clrs = plotly.colors.DEFAULT_PLOTLY_COLORS\n",
    "qs_client = Client()\n",
    "\n",
    "#Remove warning messages\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "# Convert builtby to datetime\n",
    "builtby_date = pd.to_datetime(builtby, format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query ML Screen and Cycle Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query cycle metrics\n",
    "initial_softstart1C_recipes = [15802]\n",
    "softstart1C_charge_capacity_fraction = 0.955\n",
    "softstart1C_dvdt = -4.0\n",
    "softstart1C_delta_dvdt = 2\n",
    "softstart1C_CE = 0.98\n",
    "softstart1C_ceiling_hold_time = 3600\n",
    "\n",
    "final_softstart1C_recipes = [15813]\n",
    "softstart1C_charge_capacity_fraction = 0.955\n",
    "softstart1C_dvdt = -4.0\n",
    "softstart1C_delta_dvdt = 2\n",
    "softstart1C_CE = 0.98\n",
    "softstart1C_ceiling_hold_time = 3600\n",
    "\n",
    "screen_softstart1C_recipes = [15691, 15696]\n",
    "softstart1C_charge_capacity_fraction = 0.955\n",
    "softstart1C_dvdt = -4.0\n",
    "softstart1C_delta_dvdt = 2\n",
    "softstart1C_CE = 0.98\n",
    "softstart1C_ceiling_hold_time = 3600\n",
    "\n",
    "screen_fastcharge = [14445, 15697]\n",
    "fastcharge_charge_capacity_fraction = 0.955\n",
    "fastcharge_dvdt = -10\n",
    "fastcharge_delta_dvdt = 2\n",
    "fastcharge_CE = 0.98\n",
    "fastcharge_ceiling_hold_time = 3600\n",
    "\n",
    "screen_Co3 = [13708, 15618, 14446]  # , 13213,13197, 13708, 13345, ]\n",
    "Co3_charge_capacity = 202\n",
    "Co3_dvdt = -10\n",
    "Co3_charge_capacity_fraction = 1.04\n",
    "Co3_charge_capacity_fraction_cycle = 1.01\n",
    "\n",
    "reliability_recipes = [13720, 13706, 14398, 14633, 14645, 14599]\n",
    "reliability_charge_capacity = 195\n",
    "reliability_dvdt = -50\n",
    "\n",
    "alct_reliability_recipes = [14444, 14745, 14781]\n",
    "alct_reliability_charge_capacity = 240\n",
    "alct_reliability_dvdt = -20\n",
    "\n",
    "\n",
    "lowtemp_reliability_recipes = [14654]\n",
    "lowtemp_reliability_charge_capacity = 180\n",
    "lowtemp_reliability_dvdt = -5\n",
    "\n",
    "\n",
    "# Query data\n",
    "conn = qs_client.get_mysql_engine()\n",
    "\n",
    "recipes = \"|\".join(\n",
    "    [\n",
    "        str(x)\n",
    "        for x in (\n",
    "            screen_Co3\n",
    "            + initial_softstart1C_recipes\n",
    "            + final_softstart1C_recipes\n",
    "            # + screen_Co3_RPT\n",
    "            + screen_softstart1C_recipes\n",
    "            + screen_fastcharge\n",
    "           \n",
    "            # + reliability_recipes\n",
    "            # + alct_reliability_recipes\n",
    "            # + reliability_track_cycle_charge\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_raw = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  device_structure.displayname AS samplename,\n",
    "  test_run_E12_cycle.VoltagePostCeilingRestEndDVdt * 1E6 AS dvdt,\n",
    "  test_run_E12_cycle.CapacityChargeActiveMassSpecific AS 'AMSChargeCapacity',\n",
    "  test_run_E12_cycle.CapacityDischargeActiveMassSpecific AS 'AMSDischargeCapacity',\n",
    "  test_run_E12_cycle.CapacityDischarge AS 'DischargeCapacity',\n",
    "  test_run_E12_cycle.CapacityCharge AS 'ChargeCapacity',\n",
    "  test_run_E12_cycle.EnergyDischarge AS 'DischargeEnergy',\n",
    "  test_run_E12_cycle.CapacityChargeFraction AS 'ChargeCapacityFraction',\n",
    "  test_run_E12_cycle.CoulombicEfficiency AS 'CE',\n",
    "  test_run_E12_cycle.AsrDcChargeMedian AS 'MedChargeASR',\n",
    "  test_run_E12_cycle.AsrDcDischargeMedian AS 'MedDischargeASR',\n",
    "  (test_run_E12_cycle.AsrDcChargeMedian/test_run_E12_cycle.AsrDcDischargeMedian) AS 'ASR_ratio',\n",
    "  test_run_E12_cycle.TimeCeilingHold AS 'CeilingHoldTime',\n",
    "  test_run_E12_cycle.VoltageEndCeilingRest AS 'CeilingRestVoltage',\n",
    "  test_run_E12_cycle.`index` AS 'CycleIndex',\n",
    "  test_run.`Index` AS 'RunIndex',\n",
    "  test_run.idtest_recipe,\n",
    "  test_run_E12_cycle.datetime_start AS 'TestCycleStart',\n",
    "  test_run_E12_cycle.datetime_end AS 'TestCycleEnd',\n",
    "  test_run_E12_cycle.IsShorted AS 'HardShort',\n",
    "  test_run_E12_cycle.idtest_run_E12_cycle,\n",
    "  test_run_E12.ProcessorAssumedCapacity_mAh AS 'ProcessorAssumedCapacity',\n",
    "  test_run_E12.ocv_initial AS 'OCVInitial',\n",
    "  process_flow.description AS 'ProcessDescription',\n",
    "  process.started AS 'cell_build_time',\n",
    "  tool.displayname AS Tool,\n",
    "  test_run.Channel\n",
    "FROM test_run_E12_cycle\n",
    "  INNER JOIN test_run_E12 ON test_run_E12_cycle.idtest_run_E12 = test_run_E12.idtest_run_E12\n",
    "  INNER JOIN test_run ON test_run_E12.idtest_run = test_run.idtest_run\n",
    "  INNER JOIN test_setup_E12 ON test_run_E12.idtest_setup_E12 = test_setup_E12.idtest_setup_E12\n",
    "  INNER JOIN test_request ON test_run.idtest_request = test_request.idtest_request\n",
    "  INNER JOIN device_structure ON test_run.iddevice = device_structure.iddevice\n",
    "  INNER JOIN process ON device_structure.idprocess_createdby = process.idprocess\n",
    "  INNER JOIN process_flow ON process_flow.idprocess_flow = process.idprocess_flow\n",
    "  INNER JOIN tool ON test_run.idtool=tool.idtool\n",
    "WHERE \n",
    "device_structure.displayname REGEXP %(search)s\n",
    "AND test_run_E12_cycle.CapacityCharge > 1\n",
    "AND NOT device_structure.displayname REGEXP %(exclude)s\n",
    "AND test_run.idtest_recipe REGEXP (%(recipe)s)\n",
    "\n",
    "\"\"\",\n",
    "    conn,\n",
    "    params={\"search\": search, \"recipe\": recipes, \"exclude\": exclude},\n",
    ")\n",
    "\n",
    "df_raw = df_raw.sort_values([\"RunIndex\", \"CycleIndex\"], ascending=True)\n",
    "\n",
    "# Determine if the cycle was stopped on short (more efficient method than to query the database)\n",
    "df_raw[\"CumulativeCycle\"] = 1\n",
    "df_raw.CumulativeCycle = df_raw.groupby(\"samplename\").CumulativeCycle.cumsum()\n",
    "\n",
    "df_raw[\"CumulativeCycle_Rel\"] = 1\n",
    "# df_raw.loc[\n",
    "#     df_raw[\"idtest_recipe\"].isin(reliability_recipes + alct_reliability_recipes),\n",
    "#     \"CumulativeCycle_Rel\",\n",
    "# ] = (\n",
    "#     df_raw[df_raw[\"idtest_recipe\"].isin(reliability_recipes + alct_reliability_recipes)]\n",
    "#     .groupby(\"samplename\")\n",
    "#     .CumulativeCycle_Rel.cumsum()\n",
    "# )\n",
    "\n",
    "df_raw.reset_index(inplace=True)\n",
    "\n",
    "df_raw[\"last_cycle\"] = (\n",
    "    df_raw.groupby(\"samplename\")[\"CumulativeCycle\"].transform(max)\n",
    "    == df_raw[\"CumulativeCycle\"]\n",
    ")\n",
    "\n",
    "df_raw[\"StoppedOnShort\"] = (\n",
    "    df_raw[\"DischargeCapacity\"].isnull()\n",
    "    & df_raw[\"last_cycle\"]\n",
    "    & df_raw[\"TestCycleEnd\"].notnull()\n",
    ")\n",
    "\n",
    "# df_raw.to_csv(\"df_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cycle metrics dataframe\n",
    "# ===========================================================================================\n",
    "# ======================        CYCLE METRICS CALCULATION          ==========================\n",
    "# ===========================================================================================\n",
    "\n",
    "df_cyc = df_raw.copy()\n",
    "\n",
    "df_cyc[\"batch\"] = df_cyc[\"samplename\"].str.slice(stop=13)\n",
    "df_cyc[\"process\"] = df_cyc[\"samplename\"].str.slice(stop=8)\n",
    "df_cyc[\"experiment\"] = df_cyc[\"samplename\"].str.slice(stop=6)\n",
    "df_cyc[\"project\"] = df_cyc[\"samplename\"].str.slice(stop=3)\n",
    "\n",
    "\n",
    "df_cyc['Screen_Recipe_v2'] = df_cyc.groupby(\"samplename\")['idtest_recipe'].transform(lambda x: 15802 in x.unique())\n",
    "\n",
    "df_cyc = df_cyc[~((df_cyc['Screen_Recipe_v2']) & (df_cyc['idtest_recipe'].isin([15691, 15696])))]\n",
    "\n",
    "# group by sample and check if alct_reliability_recipes is in idtest_recipe\n",
    "df_cyc[\"alct_test\"] = df_cyc.groupby(\"batch\")[\"idtest_recipe\"].transform(\n",
    "    lambda x: x.isin(alct_reliability_recipes).any()\n",
    ")\n",
    "\n",
    "df_cyc = df_cyc.set_index(\"samplename\")\n",
    "\n",
    "\n",
    "df_cyc[\"AMSDischargeCapactiy_1C\"] = (\n",
    "    df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes), [\"AMSDischargeCapacity\"]\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .min()\n",
    ")\n",
    "\n",
    "df_cyc[\"DischargeCapactiy_1C\"] = (\n",
    "    df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes), [\"DischargeCapacity\"]\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .min()\n",
    ")\n",
    "\n",
    "df_cyc[\"ChargeCapacity_1C\"] = (\n",
    "    df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes), [\"ChargeCapacity\"]\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .max()\n",
    ")\n",
    "\n",
    "df_cyc[\"AMSDischargeCapactiy_Co3\"] = (\n",
    "    df_cyc.loc[df_cyc.idtest_recipe.isin(screen_Co3), [\"AMSDischargeCapacity\"]]\n",
    "    .groupby(\"samplename\")\n",
    "    .min()\n",
    ")\n",
    "\n",
    "df_cyc[\"DischargeCapactiy_Co3\"] = (\n",
    "    df_cyc.loc[df_cyc.idtest_recipe.isin(screen_Co3), [\"DischargeCapacity\"]]\n",
    "    .groupby(\"samplename\")\n",
    "    .min()\n",
    ")\n",
    "\n",
    "df_cyc[\"MedDischargeASR_1C\"] = (\n",
    "    df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes), [\"MedDischargeASR\"]\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .last()\n",
    ")\n",
    "\n",
    "df_cyc[\"MedDischargeASR_1C_delta\"] = np.abs(\n",
    "    df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes)\n",
    "        & (df_cyc[\"CycleIndex\"] > 1),\n",
    "        [\"MedDischargeASR\"],\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .max()\n",
    "    - df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes)\n",
    "        & (df_cyc[\"CycleIndex\"] > 1),\n",
    "        [\"MedDischargeASR\"],\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .min()\n",
    ")\n",
    "\n",
    "\n",
    "df_cyc[\"dVdt_delta_1C\"] = np.abs(\n",
    "    df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes)\n",
    "        & (df_cyc[\"CycleIndex\"] > 1),\n",
    "        [\"dvdt\"],\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .min()\n",
    "    - df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes)\n",
    "        & (df_cyc[\"CycleIndex\"] > 1),\n",
    "        [\"dvdt\"],\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .max()\n",
    ")\n",
    "\n",
    "df_cyc[\"dVdt_delta_fastcharge\"] = np.abs(\n",
    "    df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_fastcharge + screen_softstart1C_recipes)\n",
    "        & (df_cyc[\"CycleIndex\"] > 1),\n",
    "        [\"dvdt\"],\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .min()\n",
    "    - df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_fastcharge + screen_softstart1C_recipes)\n",
    "        & (df_cyc[\"CycleIndex\"] > 1),\n",
    "        [\"dvdt\"],\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .max()\n",
    ")\n",
    "\n",
    "\n",
    "df_cyc[\"dVdt_1C\"] = (\n",
    "    df_cyc.loc[df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes), [\"dvdt\"]]\n",
    "    .groupby(\"samplename\")\n",
    "    .min()\n",
    ")\n",
    "\n",
    "\n",
    "df_cyc[\"CeilingHoldTime_1C\"] = (\n",
    "    df_cyc.loc[\n",
    "        df_cyc.idtest_recipe.isin(screen_softstart1C_recipes),\n",
    "        [\"CeilingHoldTime\"],\n",
    "    ]\n",
    "    .groupby(\"samplename\")\n",
    "    .last()\n",
    ")\n",
    "\n",
    "df_cyc[\"CE_1C\"] = (\n",
    "    df_cyc.loc[df_cyc.idtest_recipe.isin(screen_softstart1C_recipes+final_softstart1C_recipes), [\"CE\"]]\n",
    "    .groupby(\"samplename\")\n",
    "    .last()\n",
    ")\n",
    "\n",
    "\n",
    "df_cyc = df_cyc.reset_index()\n",
    "\n",
    "# If it stopped on short, it failed\n",
    "df_cyc[\"Failed\"] = df_cyc[\"StoppedOnShort\"] == 1\n",
    "df_cyc[\"Failed_reliability\"] = df_cyc[\"StoppedOnShort\"] == 1\n",
    "\n",
    "\n",
    "# Initial Soft-start 1C-1C\n",
    "# 1C-1C\n",
    "df_cyc.loc[\n",
    "    (df_cyc.idtest_recipe.isin(initial_softstart1C_recipes))\n",
    "    & (\n",
    "        (\n",
    "            # (df_cyc.AMSChargeCapacity > softstart1C_charge_capacity)\n",
    "            (df_cyc.ChargeCapacityFraction > softstart1C_charge_capacity_fraction)\n",
    "            # | (df_cyc.AMSChargeCapacity < 50)\n",
    "        )\n",
    "    #     | (df_cyc.dvdt <= softstart1C_dvdt)\n",
    "    #     | ((df_cyc.CE < softstart1C_CE) & (df_cyc.AMSDischargeCapacity > 140))\n",
    "    #     | (df_cyc.dVdt_delta_1C > softstart1C_delta_dvdt)\n",
    "    #     | (df_cyc.CeilingHoldTime > softstart1C_ceiling_hold_time)\n",
    "    ),\n",
    "    \"Failed\",\n",
    "] = True\n",
    "\n",
    "# Final Soft-start 1C-1C\n",
    "\n",
    "df_cyc.loc[\n",
    "    (df_cyc.idtest_recipe.isin(final_softstart1C_recipes))\n",
    "    & (\n",
    "        (\n",
    "            # (df_cyc.AMSChargeCapacity > softstart1C_charge_capacity)\n",
    "            (df_cyc.ChargeCapacityFraction > softstart1C_charge_capacity_fraction)\n",
    "            # | (df_cyc.AMSChargeCapacity < 50)\n",
    "        )\n",
    "    #     | (df_cyc.dvdt <= softstart1C_dvdt)\n",
    "    #     | ((df_cyc.CE < softstart1C_CE) & (df_cyc.AMSDischargeCapacity > 140))\n",
    "    #     | (df_cyc.dVdt_delta_1C > softstart1C_delta_dvdt)\n",
    "    #     | (df_cyc.CeilingHoldTime > softstart1C_ceiling_hold_time)\n",
    "    ),\n",
    "    \"Failed\",\n",
    "] = True\n",
    "\n",
    "\n",
    "\n",
    "# Soft-start 1C-1C\n",
    "# 1C-1C\n",
    "df_cyc.loc[\n",
    "    (df_cyc.idtest_recipe.isin(screen_softstart1C_recipes))\n",
    "    & (\n",
    "        (\n",
    "            # (df_cyc.AMSChargeCapacity > softstart1C_charge_capacity)\n",
    "            (df_cyc.ChargeCapacityFraction > softstart1C_charge_capacity_fraction)\n",
    "            # | (df_cyc.AMSChargeCapacity < 50)\n",
    "        )\n",
    "    #     | (df_cyc.dvdt <= softstart1C_dvdt)\n",
    "    #     | ((df_cyc.CE < softstart1C_CE) & (df_cyc.AMSDischargeCapacity > 140))\n",
    "    #     | (df_cyc.dVdt_delta_1C > softstart1C_delta_dvdt)\n",
    "    #     | (df_cyc.CeilingHoldTime > softstart1C_ceiling_hold_time)\n",
    "    ),\n",
    "    \"Failed\",\n",
    "] = True\n",
    "\n",
    "# Fast charge\n",
    "df_cyc.loc[\n",
    "    (df_cyc.idtest_recipe.isin(screen_fastcharge))\n",
    "    & (\n",
    "        (\n",
    "            (df_cyc.ChargeCapacityFraction > fastcharge_charge_capacity_fraction)\n",
    "            # | (df_cyc.AMSChargeCapacity < 50)\n",
    "        )\n",
    "        | (df_cyc.dvdt <= fastcharge_dvdt)\n",
    "        # | ((df_cyc.CE < fastcharge_CE) & (df_cyc.AMSDischargeCapacity > 140))\n",
    "        # | (df_cyc.dVdt_delta_fastcharge > fastcharge_delta_dvdt)\n",
    "        # | (df_cyc.CeilingHoldTime > fastcharge_ceiling_hold_time)\n",
    "    ),\n",
    "    \"Failed\",\n",
    "] = True\n",
    "\n",
    "# C/3 cycle\n",
    "df_cyc.loc[\n",
    "    (df_cyc.idtest_recipe.isin(screen_Co3))\n",
    "    & (\n",
    "        (\n",
    "            (df_cyc.AMSChargeCapacity > Co3_charge_capacity)\n",
    "            # | (df_cyc.AMSChargeCapacity < 100)\n",
    "        )\n",
    "        | (df_cyc.dvdt <= Co3_dvdt)\n",
    "    ),\n",
    "    \"Failed\",\n",
    "] = True\n",
    "\n",
    "\n",
    "\n",
    "# Reliability\n",
    "df_cyc.loc[\n",
    "    (df_cyc.idtest_recipe.isin(reliability_recipes))\n",
    "    & (\n",
    "        (df_cyc.AMSChargeCapacity > reliability_charge_capacity)\n",
    "        | (df_cyc.dvdt <= reliability_dvdt)\n",
    "    ),\n",
    "    \"Failed_reliability\",\n",
    "] = True\n",
    "\n",
    "# ALCT Reliability\n",
    "df_cyc.loc[\n",
    "    (df_cyc.idtest_recipe.isin(alct_reliability_recipes))\n",
    "    & (\n",
    "        (df_cyc.AMSChargeCapacity > alct_reliability_charge_capacity)\n",
    "        | (df_cyc.dvdt <= alct_reliability_dvdt)\n",
    "    ),\n",
    "    \"Failed_reliability\",\n",
    "] = True\n",
    "\n",
    "\n",
    "df_cyc = df_cyc.merge(\n",
    "    df_cyc[[\"samplename\", \"Failed\", \"Failed_reliability\"]].groupby(\"samplename\").max(),\n",
    "    suffixes=[\"\", \"_any\"],\n",
    "    right_index=True,\n",
    "    left_on=\"samplename\",\n",
    ")\n",
    "\n",
    "\n",
    "df_cyc[\"ShortEvent\"] = df_cyc.Failed_any | df_cyc.Failed_reliability\n",
    "\n",
    "\n",
    "df_cyc_screen = pd.concat(\n",
    "    [\n",
    "        df_cyc.loc[\n",
    "            (df_cyc.ShortEvent == True)\n",
    "            & ((df_cyc.Failed == True) | (df_cyc.Failed_reliability == True))\n",
    "        ]\n",
    "        .groupby(\"samplename\")\n",
    "        .first(),\n",
    "        df_cyc.loc[(df_cyc.ShortEvent == False)].groupby(\"samplename\").last(),\n",
    "    ]\n",
    ")\n",
    "df_cyc_screen[\"EventCycle\"] = df_cyc_screen.CumulativeCycle\n",
    "df_cyc_screen = df_cyc_screen[~df_cyc_screen.index.duplicated()]\n",
    "\n",
    "\n",
    "df_master = pd.DataFrame(df_cyc[\"samplename\"].unique(), columns=[\"samplename\"]).join(\n",
    "    df_cyc_screen, on=\"samplename\", how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "df_master[\"Build Count\"] = 1\n",
    "\n",
    "df_master[\"Initial 1C Count\"] = np.where(\n",
    "    (\n",
    "        (\n",
    "            (df_master.ShortEvent == True)\n",
    "            & (df_master.idtest_recipe.isin(initial_softstart1C_recipes))\n",
    "        )\n",
    "    )\n",
    "    & (df_master.CumulativeCycle < 50),\n",
    "    0,\n",
    "    1,\n",
    ")\n",
    "\n",
    "\n",
    "df_master[\"1C Count\"] = np.where(\n",
    "    (\n",
    "        (\n",
    "            (df_master.ShortEvent == True)\n",
    "            & (df_master.idtest_recipe.isin(screen_softstart1C_recipes))\n",
    "        )\n",
    "    )\n",
    "    & (df_master.CumulativeCycle < 50),\n",
    "    0,\n",
    "    1,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df_master[\"Fast-Charge Count\"] = np.where(\n",
    "    (\n",
    "        (\n",
    "            (\n",
    "                (df_master.ShortEvent == True)\n",
    "                & df_master.idtest_recipe.isin(screen_fastcharge)\n",
    "            )\n",
    "            | ((df_master[\"1C Count\"] == 0) | (df_master[\"Initial 1C Count\"] == 0))\n",
    "        )\n",
    "    )\n",
    "    & (df_master.CumulativeCycle < 50),\n",
    "    0,\n",
    "    1,\n",
    ")\n",
    "\n",
    "df_master[\"Final 1C Count\"] = np.where(\n",
    "    (\n",
    "        ((df_master.ShortEvent == True) & (df_master.idtest_recipe.isin(final_softstart1C_recipes)))\n",
    "        | (df_master[\"Fast-Charge Count\"] == 0)\n",
    "    )\n",
    "    & (df_master.CumulativeCycle < 30),\n",
    "    0,\n",
    "    1,\n",
    ")\n",
    "\n",
    "\n",
    "df_master[\"C/3 Count\"] = np.where(\n",
    "    (\n",
    "        ((df_master.ShortEvent == True) & (df_master.idtest_recipe.isin(screen_Co3)))\n",
    "        | ((df_master[\"Fast-Charge Count\"] == 0) | (df_master[\"Final 1C Count\"] == 0))\n",
    "    )\n",
    "    & (df_master.CumulativeCycle < 30),\n",
    "    0,\n",
    "    1,\n",
    ")\n",
    "\n",
    "df_master[\"Yield Count\"] = df_master[\"C/3 Count\"]\n",
    "\n",
    "#df_master[\"Yield Count\"] = 1\n",
    "\n",
    "df_master[\"Initial 1C Count\"] = df_master[\"Initial 1C Count\"] * df_master[\"batch\"].apply(\n",
    "    lambda x: df_cyc[df_cyc[\"batch\"] == x][\"idtest_recipe\"]\n",
    "    .isin(initial_softstart1C_recipes)\n",
    "    .astype(int)\n",
    "    .max()\n",
    ")\n",
    "\n",
    "df_master[\"Final 1C Count\"] = df_master[\"Final 1C Count\"] * df_master[\"batch\"].apply(\n",
    "    lambda x: df_cyc[df_cyc[\"batch\"] == x][\"idtest_recipe\"]\n",
    "    .isin(final_softstart1C_recipes)\n",
    "    .astype(int)\n",
    "    .max()\n",
    ")\n",
    "\n",
    "\n",
    "df_master[\"1C Count\"] = df_master[\"1C Count\"] * df_master[\"batch\"].apply(\n",
    "    lambda x: df_cyc[df_cyc[\"batch\"] == x][\"idtest_recipe\"]\n",
    "    .isin(screen_softstart1C_recipes)\n",
    "    .astype(int)\n",
    "    .max()\n",
    ")\n",
    "\n",
    "df_master[\"Fast-Charge Count\"] = df_master[\"Fast-Charge Count\"] * df_master[\"batch\"].apply(\n",
    "    lambda x: df_cyc[df_cyc[\"batch\"] == x][\"idtest_recipe\"]\n",
    "    .isin(screen_fastcharge)\n",
    "    .astype(int)\n",
    "    .max()\n",
    ")\n",
    "\n",
    "\n",
    "df_master[\"C/3 Count\"] = df_master[\"C/3 Count\"] * df_master[\"batch\"].apply(\n",
    "    lambda x: df_cyc[df_cyc[\"batch\"] == x][\"idtest_recipe\"]\n",
    "    .isin(screen_Co3)\n",
    "    .astype(int)\n",
    "    .max()\n",
    ")\n",
    "\n",
    "df_master[\"Reliability Short\"] = np.nan\n",
    "\n",
    "df_master.loc[\n",
    "    (df_master.ShortEvent == True)\n",
    "    & (df_master.idtest_recipe.isin(reliability_recipes + alct_reliability_recipes+lowtemp_reliability_recipes))\n",
    "    & (df_master[\"Yield Count\"] == 1),\n",
    "    \"Reliability Short\",\n",
    "] = True\n",
    "\n",
    "df_master.loc[\n",
    "    (df_master.ShortEvent == False)\n",
    "    & (df_master.idtest_recipe.isin(reliability_recipes + alct_reliability_recipes+lowtemp_reliability_recipes))\n",
    "    & (df_master[\"Yield Count\"] == 1),\n",
    "    \"Reliability Short\",\n",
    "] = False\n",
    "\n",
    "\n",
    "df_master.reset_index(inplace=True)\n",
    "\n",
    "df_master[\"cell_build_date\"] = df_master.groupby(\"process\")[\n",
    "    \"cell_build_time\"\n",
    "].transform(\"min\")\n",
    "df_master[\"cell_build_WW\"] = (\n",
    "    df_master[\"cell_build_date\"].dt.isocalendar().year.astype(str)\n",
    "    + \"WW\"\n",
    "    + df_master[\"cell_build_date\"].dt.isocalendar().week.astype(str)\n",
    ")\n",
    "\n",
    "df_master[\"cell_build_date\"] = df_master[\"cell_build_date\"].dt.date\n",
    "\n",
    "df_master[\"cell flow + date\"] = (\n",
    "    df_master[\"process\"] + \",<br>\" + df_master[\"cell_build_date\"].astype(str)\n",
    ")\n",
    "\n",
    "df_master[\"cell_tier_group\"] = \"Spec Fail\"\n",
    "\n",
    "# Filter the DataFrame to keep only rows where cell_build_date is on or after builtby_date\n",
    "df_master = df_master[df_master['cell_build_date'] >= builtby_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tier ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Ground Truth Tiering of each cell in the ML pouches\n",
    "\n",
    "# Query dataframe from database\n",
    "MLgen = genealogy_v2.get_genealogy_2L('APD|ML|UC|QSC', conn) # \n",
    "CellsInML = df_master.merge(MLgen, left_on='samplename', right_on='6L_cell_id', how='left')\n",
    "CellsInML = CellsInML[['samplename', '2L_cell_id']].rename(columns={'2L_cell_id': 'Cell ID'})\n",
    "\n",
    "qs_client = Client()\n",
    "#Pull cell metrology data from datahub, both standard/auto metrology and manual review\n",
    "dfctq = qs_client.data_hub.get_dataset(dataset = 'MFG-60L-UC-CTQ') ## standard metro\n",
    "dfctq_filtered = dfctq[dfctq['US_id'].isin(CellsInML['Cell ID'])]\n",
    "yielded_dfctq = dfctq_filtered[dfctq_filtered['unit_cell_test_yield'] == 1] #keep cells that yielded\n",
    "\n",
    "dfmr = qs_client.data_hub.get_dataset(dataset = 'MFG-60L-UC-MR') ## manual review\n",
    "dfmr_filtered = dfmr[dfmr['US_id'].isin(CellsInML['Cell ID'])]\n",
    "yielded_dfmr = dfmr_filtered[dfmr_filtered['unit_cell_test_yield'] == 1] #keep cells that yielded\n",
    "\n",
    "\n",
    "# First, merge the DataFrames on 'US_id' to align rows\n",
    "merged_df = yielded_dfctq.merge(yielded_dfmr[['US_id', 'edge_thickness_tier_us_mr', 'A1_anode_tier_top_us_mr', 'A1_anode_tier_bottom_us_mr',\n",
    "                                              'cathode_alignment_custom_model_tier_us_mr', 'median_contour_catholyte_pct_us_mr', 'disposition_mr', 'failure_modes_mr']], on='US_id', how='left')\n",
    "# Then, overwrite 'edge_thickness_tier_us' in 'filtered_dfctq' where 'edge_thickness_tier_us_mr' has a value\n",
    "merged_df['edge_thickness_tier_us'] = merged_df['edge_thickness_tier_us_mr'].combine_first(merged_df['edge_thickness_tier_us'])\n",
    "# Then, overwrite 'A1_anode_tier_top_us' in 'filtered_dfctq' where 'A1_anode_tier_top_us_mr' has a value\n",
    "merged_df['A1_anode_tier_top_us'] = merged_df['A1_anode_tier_top_us_mr'].combine_first(merged_df['A1_anode_tier_top_us'])\n",
    "# Then, overwrite 'A1_anode_tier_bottom_us' in 'filtered_dfctq' where 'A1_anode_tier_bottom_us_mr' has a value\n",
    "merged_df['A1_anode_tier_bottom_us'] = merged_df['A1_anode_tier_bottom_us_mr'].combine_first(merged_df['A1_anode_tier_bottom_us'])\n",
    "# Then, overwrite 'A1_anode_tier_bottom_us' in 'filtered_dfctq' where 'A1_anode_tier_bottom_us_mr' has a value\n",
    "merged_df['cathode_alignment_custom_model_tier_us'] = merged_df['cathode_alignment_custom_model_tier_us_mr'].combine_first(merged_df['cathode_alignment_custom_model_tier_us'])\n",
    "# Then, overwrite 'A1_anode_tier_bottom_us' in 'filtered_dfctq' where 'A1_anode_tier_bottom_us_mr' has a value\n",
    "merged_df['median_contour_catholyte_pct_us'] = merged_df['median_contour_catholyte_pct_us_mr'].combine_first(merged_df['median_contour_catholyte_pct_us'])\n",
    "# Then, overwrite 'disposition_us' in 'disposition_mr' has a value\n",
    "merged_df['disposition'] = merged_df['disposition_mr'].combine_first(merged_df['disposition'])\n",
    "# Then, overwrite 'disposition_us' in 'disposition_mr' has a value\n",
    "merged_df['failure_modes'] = merged_df['failure_modes_mr'].combine_first(merged_df['failure_modes'])\n",
    "# Drop the 'edge_thickness_tier_us_mr' column if you don't need it\n",
    "dfctq_updated = merged_df.drop(columns=['edge_thickness_tier_us_mr', 'A1_anode_tier_top_us_mr', 'A1_anode_tier_bottom_us_mr',\n",
    "                                              'cathode_alignment_custom_model_tier_us_mr', 'median_contour_catholyte_pct_us_mr', 'disposition_mr','failure_modes_mr' ])\n",
    "\n",
    "#Update Final Tier of Cells\n",
    "conditions = [\n",
    "    dfctq_updated['disposition'] == 'Tier 1',\n",
    "    dfctq_updated['disposition'] == 'Tier 2',\n",
    "    dfctq_updated['disposition'] == 'Fail',\n",
    "    dfctq_updated['disposition'] == 'Scrap',\n",
    "    dfctq_updated['disposition'] == 'Missing Data',\n",
    "]\n",
    "choices = ['1', '2', '3','Scrapped', 'TBD']\n",
    "dfctq_updated['Tier'] = np.select(conditions, choices)\n",
    "\n",
    "\n",
    "\n",
    "# Merge dfctq_updated['US_id', 'Tier'] with CellsInML based on 'US_id'\n",
    "CellsInML = CellsInML.merge(dfctq_updated[['US_id', 'Tier']], \n",
    "                            left_on='Cell ID', \n",
    "                            right_on='US_id', \n",
    "                            how='left')\n",
    "\n",
    "# Assign the 'Tier' column to 'Cell Tier' and drop the extra 'US_id' column\n",
    "CellsInML['Cell Tier'] = CellsInML['Tier']\n",
    "CellsInML = CellsInML.drop(columns=['Tier', 'US_id'])\n",
    "\n",
    "# Group by \"samplename\" and find the max \"Cell Tier\" for each\n",
    "CellsInML['Cell Tier'] = pd.to_numeric(CellsInML['Cell Tier'], errors='coerce')\n",
    "FinalMLTier = CellsInML.groupby('samplename', as_index=False)['Cell Tier'].max()\n",
    "\n",
    "# Rename columns as required\n",
    "FinalMLTier.columns = ['Multilayer', 'ML Tier']\n",
    "# Convert \"ML Tier\" to integer and format as \"Tier {max Cell Tier}\"\n",
    "# Conditionally update 'ML Tier'\n",
    "FinalMLTier['ML Tier'] = np.where(\n",
    "    FinalMLTier['ML Tier'].isna(), \n",
    "    np.nan,  # Keep NaN if it was originally NaN\n",
    "    \"Tier \" + FinalMLTier['ML Tier'].fillna(0).astype(int).astype(str)\n",
    ")\n",
    "\n",
    "# Merge df_master with FinalMLTier on \"samplename\" and \"Multilayer\"\n",
    "df_master = df_master.merge(FinalMLTier, left_on='samplename', right_on='Multilayer', how='left')\n",
    "\n",
    "# Update \"cell_tier_group\" with the values from \"ML Tier\"\n",
    "df_master['cell_tier_group'] = df_master['ML Tier']\n",
    "\n",
    "# Drop the extra \"Multilayer\" and \"ML Tier\" columns\n",
    "df_master = df_master.drop(columns=['Multilayer', 'ML Tier'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ML Screen Yield, Build Tiers, Electrical Metrics, and Cycle Reliability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Yield Plots\n",
    "# =============================================================================\n",
    "# ======================        YIELD PLOTS          ==========================\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# Group by\n",
    "grouping = \"cell_build_WW\"\n",
    "#grouping = \"experiment\"\n",
    "\n",
    "# grouping = \"cell_tier_group\"\n",
    "\n",
    "data = df_master.copy()\n",
    "\n",
    "data = data[data.samplename.str.contains('MLB00[3,6]|QSC022')]\n",
    "data = data[~data.samplename.str.contains('MLB006AB')]\n",
    "\n",
    "data.loc[data.samplename.str.contains('MLB003A[F,L]-PS00-01'), 'cell_tier_group'] = 'Tier 2'\n",
    "\n",
    "data.loc[data.samplename.str.contains('QSC022AD-PS00-02'), ['Fast-Charge Count', 'Final 1C Count', 'C/3 Count']] = [1,1,1]\n",
    "\n",
    "# Keep rows where 'cell_tier_group' is 'Tier 1' or 'Tier 2'\n",
    "\n",
    "data = data[data['cell_tier_group'].isin(['Tier 1'])]\n",
    "\n",
    "data[\"cell_build_WW\"]= data[\"cell_build_WW\"].str[-4:]\n",
    "\n",
    "data[\"cell_build_datetime\"] = pd.to_datetime(data[\"cell_build_date\"])\n",
    "data['date'] = data[\"cell_build_datetime\"].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "df_cyield = (\n",
    "    data[\n",
    "        [\n",
    "            grouping,\n",
    "            \"cell_build_date\",\n",
    "            \"Screen_Recipe_v2\"\n",
    "        ]\n",
    "    ]  # , \"platform\"]]  #\n",
    "    .groupby(grouping)\n",
    "    .first()\n",
    "    .join(\n",
    "        data[\n",
    "            [\n",
    "                grouping,\n",
    "                \"Build Count\",\n",
    "                \"Initial 1C Count\",\n",
    "                \"1C Count\",\n",
    "                \"Fast-Charge Count\",\n",
    "                \"Final 1C Count\",\n",
    "                \"C/3 Count\",\n",
    "                # \"Yield Count\",\n",
    "            ]\n",
    "        ]\n",
    "        .groupby(grouping)\n",
    "        .sum(),\n",
    "        how=\"right\",\n",
    "    )\n",
    "    .reset_index()\n",
    ").set_index(grouping)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_cyield[\n",
    "    [\n",
    "        \"Cells Built\",\n",
    "        \"Initial 1C Yield\",\n",
    "        \"1C Yield\",\n",
    "        \"Fast-Charge Yield\",\n",
    "        \"Final 1C Yield\",\n",
    "        \"C/3 Yield\",\n",
    "    ]\n",
    "] = 100 * df_cyield[\n",
    "    [\n",
    "        \"Build Count\",\n",
    "        \"Initial 1C Count\",\n",
    "        \"1C Count\",\n",
    "        \"Fast-Charge Count\",\n",
    "        \"Final 1C Count\",\n",
    "        \"C/3 Count\",\n",
    "        # \"Yield Count\",\n",
    "    ]\n",
    "].div(\n",
    "    df_cyield[\"Build Count\"], axis=0\n",
    ")\n",
    "\n",
    "\n",
    "df_cyield = df_cyield.sort_values(grouping)\n",
    "\n",
    "\n",
    "df_cyield_v1 = df_cyield[df_cyield[\"Screen_Recipe_v2\"] == False]\n",
    "df_cyield_v2 = df_cyield[df_cyield[\"Screen_Recipe_v2\"] == True]\n",
    "\n",
    "\n",
    "for i, df in enumerate([df_cyield_v1, df_cyield_v2]):\n",
    "\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    if i == 0:\n",
    "\n",
    "        fig = px.bar(\n",
    "            df,\n",
    "            x=df.index,\n",
    "            y=[\n",
    "                \"Cells Built\",\n",
    "                \"1C Yield\",\n",
    "                \"Fast-Charge Yield\",\n",
    "                \"C/3 Yield\",\n",
    "                # \"Fast-Charge Yield\",\n",
    "                # \"Screen Yield\",\n",
    "            ],\n",
    "            # facet_col=\"cell_build_date\",\n",
    "            barmode=\"group\",\n",
    "            title = 'Screen v1 Yield',\n",
    "        )\n",
    "    \n",
    "    if i == 1:\n",
    "\n",
    "         fig = px.bar(\n",
    "            df,\n",
    "            x=df.index,\n",
    "            y=[\n",
    "                \"Cells Built\",\n",
    "                \"Initial 1C Yield\",\n",
    "                \"Fast-Charge Yield\",\n",
    "                \"Final 1C Yield\",\n",
    "                \"C/3 Yield\",\n",
    "                # \"Fast-Charge Yield\",\n",
    "                # \"Screen Yield\",\n",
    "            ],\n",
    "            # facet_col=\"cell_build_date\",\n",
    "            barmode=\"group\",\n",
    "            title = 'Screen v2 Yield',\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        categoryorder=\"array\",\n",
    "        categoryarray=df.index.unique(),\n",
    "    )\n",
    "\n",
    "    # Create the text annotations with optional bold formatting\n",
    "    build_count_text = [f\"N= {n}\" for n in df[\"Build Count\"]]\n",
    "    # rpt_count_text = [f\"<b>N= {n}</b>\" for n in df_cyield[\"C/3 Count\"]]\n",
    "    C_3_count_text = [f\"<b>{round(n,1)}%</b>\" for n in df[\"C/3 Yield\"]]\n",
    "    # one_c_count_text = f\"<b>N= {df_cyield['1C Count'].values}</b>\" \n",
    "\n",
    "    # Update the traces with the new text lists\n",
    "    fig.data[0].text = build_count_text\n",
    "    # fig.data[1].text = rpt_count_text\n",
    "\n",
    "    if i == 0:\n",
    "        fig.data[3].text = C_3_count_text\n",
    "    else:\n",
    "        fig.data[4].text = C_3_count_text\n",
    "\n",
    "\n",
    "    # fig.data[3].text = C_3_count_text\n",
    "\n",
    "\n",
    "    fig.update_traces(textposition=\"inside\", textfont_size=20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=grouping,\n",
    "        yaxis_title=\"Screen yield (%)\",\n",
    "        font=dict(\n",
    "            size=18,\n",
    "        ),\n",
    "        legend={\"title_text\": \"\"},\n",
    "        yaxis_range=[0, 100],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_yaxes(tickfont=dict(size=20))\n",
    "    fig.update_xaxes(tickfont=dict(size=24))\n",
    "\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        categoryorder=\"array\",\n",
    "    #    categoryarray=['APD256AA', 'APD256AB', 'MLB000AB', 'MLB000AC', 'MLB000AD' ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # add grey dotted line at 80% yield\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=-0.5,\n",
    "        x1=df.shape[0] - 0.5,\n",
    "        y0=80,\n",
    "        y1=80,\n",
    "        line=dict(color=\"grey\", width=2, dash=\"dot\"),\n",
    "    )\n",
    "\n",
    "\n",
    "    # change the bar colors\n",
    "    colors = [\n",
    "        px.colors.qualitative.Plotly[2],\n",
    "        px.colors.qualitative.Plotly[5],\n",
    "        px.colors.qualitative.Plotly[3],\n",
    "        px.colors.qualitative.Plotly[6],\n",
    "        px.colors.qualitative.Plotly[4],\n",
    "        px.colors.qualitative.Plotly[0],\n",
    "        px.colors.qualitative.Plotly[1],\n",
    "    ]\n",
    "    for i in range(len(fig.data)):\n",
    "        fig.data[i].marker.color = colors[i]\n",
    "\n",
    "    fig.show(renderer=\"browser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master[df_master['samplename'].str.contains('QSC022') & (df_master['C/3 Count'] == 1)][['samplename', 'C/3 Count']].to_csv('QSC022_CellList.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Stacked Bar Chart for Cells Built by Tier\n",
    "\n",
    "df_master2 = df_master[df_master['samplename'].str.contains('QSC022')]\n",
    "\n",
    "df_master2.loc[df_master2.samplename.str.contains('QSC022AA-PS00-02'), 'cell_tier_group'] = 'Tier 1'\n",
    "\n",
    "\n",
    "df_master2[\"cell_build_datetime\"] = pd.to_datetime(df_master2[\"cell_build_date\"])\n",
    "df_master2['date'] = df_master2[\"cell_build_datetime\"].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "df_master2 = df_master2.sort_values(\"cell_build_WW\")\n",
    "\n",
    "grouped_data = df_master2.groupby([\"date\", \"cell_tier_group\"])['Build Count'].sum().unstack(fill_value=0)\n",
    "\n",
    "\n",
    "# Creating a plotly stacked bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add each tier as a separate trace with custom pastel colors\n",
    "fig.add_trace(go.Bar(\n",
    "    x=grouped_data.index,\n",
    "    y=grouped_data['Tier 1'],\n",
    "    name='Tier 1',\n",
    "    marker_color=px.colors.qualitative.Pastel1[2]  # Pastel green for Tier 1\n",
    "))\n",
    "\n",
    "# check if Tier 2 and Tier 3 exist in the grouped data\n",
    "if 'Tier 2' in grouped_data.columns:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=grouped_data.index,\n",
    "        y=grouped_data['Tier 2'],\n",
    "        name='Tier 2',\n",
    "        marker_color=px.colors.qualitative.Pastel1[1]  # Pastel blue for Tier 2\n",
    "    ))\n",
    "\n",
    "if 'Tier 3' in grouped_data.columns:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=grouped_data.index,\n",
    "        y=grouped_data['Tier 3'],\n",
    "        name='Tier 3',\n",
    "        marker_color=px.colors.qualitative.Pastel1[0]  # Pastel red for Tier 3\n",
    "    ))\n",
    "\n",
    "# Update the layout for stacked bar\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    title='Total Build Count per Batch, Stacked by Tier',\n",
    "    xaxis_title='Batch',\n",
    "    yaxis_title='Total Build Count'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(range=[0,8], tickfont=dict(size=20), title_font=dict(size=24))\n",
    "fig.update_xaxes(tickfont=dict(size=20), title_font=dict(size=16))\n",
    "\n",
    "# add total count label outside each bar\n",
    "\n",
    "for i, batch in enumerate(grouped_data.index):\n",
    "    fig.add_annotation(\n",
    "        x=batch,\n",
    "        y=grouped_data.loc[batch].sum(),\n",
    "        text=f\"{grouped_data.loc[batch].sum()}\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=20),\n",
    "        yshift=10\n",
    "    )\n",
    "\n",
    "# increase the font of the legend\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        title='',\n",
    "        font=dict(\n",
    "            size=24\n",
    "        )\n",
    "    )   \n",
    ")\n",
    "\n",
    "\n",
    "# Show the figure\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Cell Metrics\n",
    "# =============================================================================\n",
    "# ========================        CELL METRICS          =======================\n",
    "# =============================================================================\n",
    "\n",
    "grouping = \"process\"\n",
    "color_by = \"experiment\"\n",
    "\n",
    "data = df_master.copy()\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    1,\n",
    "    2,\n",
    "    horizontal_spacing=0.12,\n",
    "    vertical_spacing=0.1,\n",
    "    shared_xaxes=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# create a color dictionary for each color_by category\n",
    "color = dict(zip(data[color_by].unique(), px.colors.qualitative.Plotly*5))\n",
    "color.keys()\n",
    "data[color_by].unique()\n",
    "\n",
    "# Set a flag to ensure legend items are added only once\n",
    "legend_added = {key: False for key in data[color_by].unique()}\n",
    "\n",
    "for label, group in data[data['C/3 Count']==1].groupby(grouping):\n",
    "    for color_value, group_color in group.groupby(color_by):\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group_color[grouping],\n",
    "                y=group_color[\"AMSDischargeCapactiy_Co3\"],\n",
    "                quartilemethod=\"linear\",\n",
    "                name=color_value,\n",
    "                text=group_color[\"samplename\"],\n",
    "                showlegend=not legend_added[color_value],\n",
    "                fillcolor=color[color_value],\n",
    "                line=dict(color=\"black\"),\n",
    "            ),\n",
    "            1,\n",
    "            1,\n",
    "        )\n",
    "        legend_added[color_value] = True\n",
    "\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Discharge Capacity (mAh/g)\",\n",
    "    range=[190, 205],\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "for label, group in data[data['C/3 Count']==1].groupby(grouping):\n",
    "    for color_value, group_color in group.groupby(color_by):\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group_color[grouping],\n",
    "                y=group_color[\n",
    "                    \"DischargeCapactiy_Co3\"\n",
    "                ],  # [group[\"Final 1C Count\"] == 1]\n",
    "                quartilemethod=\"linear\",\n",
    "                name=color_value,\n",
    "                text=group_color[\"samplename\"],\n",
    "                showlegend=not legend_added[color_value],\n",
    "                fillcolor=color[color_value],\n",
    "                line=dict(color=\"black\"),\n",
    "            ),\n",
    "            1,\n",
    "            2,\n",
    "        )\n",
    "        legend_added[color_value] = True\n",
    "\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"C/3 Discharge Capacity (mAh)\",\n",
    "    range=[5, 7],\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "for i in range(2):\n",
    "    fig.update_yaxes(\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        linewidth=1,\n",
    "        mirror=True,\n",
    "        ticks=\"outside\",\n",
    "        row=1,\n",
    "        col=i + 1,\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        linewidth=1,\n",
    "        mirror=True,\n",
    "        ticks=\"outside\",\n",
    "        row=1,\n",
    "        col=i + 1,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"\",\n",
    "    # xaxis_title=grouping,\n",
    "    font=dict(\n",
    "        size=16,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.update_traces(boxpoints=\"all\", jitter=0.1)\n",
    "\n",
    "fig.update_xaxes(\n",
    "    categoryorder=\"array\",\n",
    "    categoryarray=data.sort_values([\"batch\"])[grouping].unique(),\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    1,\n",
    "    2,\n",
    "    horizontal_spacing=0.12,\n",
    "    vertical_spacing=0.1,\n",
    "    shared_xaxes=True,\n",
    ")\n",
    "\n",
    "# plot colors in px.colors.qualitative.Plotly\n",
    "color = dict(zip(data[color_by].unique(), px.colors.qualitative.Plotly*5))\n",
    "\n",
    "\n",
    "# Set a flag to ensure legend items are added only once\n",
    "legend_added = {key: False for key in data[color_by].unique()}\n",
    "\n",
    "for label, group in data[data['1C Count']==1].groupby(grouping):\n",
    "    for color_value, group_color in group.groupby(color_by):\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group_color[grouping],\n",
    "                y=group_color[\n",
    "                    \"dVdt_1C\"\n",
    "                ],  # [group[\"Formation Count\"] == 1]\n",
    "                quartilemethod=\"linear\",\n",
    "                name=color_value,\n",
    "                text=group_color[\"samplename\"],\n",
    "                showlegend=not legend_added[color_value],\n",
    "                fillcolor=color[color_value],\n",
    "                line=dict(color=\"black\"),\n",
    "            ),\n",
    "            1,\n",
    "            1,\n",
    "        )\n",
    "        legend_added[color_value] = True\n",
    "\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"dV/dt (ÂµV/s)\",\n",
    "    # range=[20, 30],\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "for label, group in data[data['1C Count']==1].groupby(grouping):\n",
    "    for color_value, group_color in group.groupby(color_by):\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                x=group_color[grouping],\n",
    "                y=group_color[\"MedDischargeASR_1C\"],  # [group[\"Final 1C Count\"] == 1]\n",
    "                quartilemethod=\"linear\",\n",
    "                name=color_value,\n",
    "                text=group_color[\"samplename\"],\n",
    "                showlegend=not legend_added[color_value],\n",
    "                fillcolor=color[color_value],\n",
    "                line=dict(color=\"black\"),\n",
    "            ),\n",
    "            1,\n",
    "            2,\n",
    "        )\n",
    "        legend_added[color_value] = True\n",
    "\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"1C Discharge ASR (Ohm cm<sup>2</sup>)\",\n",
    "    range=[20, 30],\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "# # add third subplot with ASR_ratio_1C\n",
    "# for label, group in data.groupby(grouping):\n",
    "#     for color_value, group_color in group.groupby(color_by):\n",
    "#         fig.add_trace(\n",
    "#             go.Box(\n",
    "#                 x=group_color[grouping],\n",
    "#                 y=group_color[\"ASR_ratio_1C\"],  # [group[\"Final 1C Count\"] == 1]\n",
    "#                 quartilemethod=\"linear\",\n",
    "#                 name=color_value,\n",
    "#                 text=group_color[\"samplename\"],\n",
    "#                 showlegend=False,\n",
    "#                 fillcolor=color[color_value],\n",
    "#                 line=dict(color=\"black\"),\n",
    "#             ),\n",
    "#             1,\n",
    "#             3,\n",
    "#         )\n",
    "\n",
    "# fig.update_yaxes(\n",
    "#     title_text=\"Charge/Discharge ASR Ratio\",\n",
    "#     range=[0.8, 1.2],\n",
    "#     row=1,\n",
    "#     col=3,\n",
    "# )\n",
    "\n",
    "for i in range(2):\n",
    "    fig.update_yaxes(\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        linewidth=1,\n",
    "        mirror=True,\n",
    "        ticks=\"outside\",\n",
    "        row=1,\n",
    "        col=i + 1,\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        linewidth=1,\n",
    "        mirror=True,\n",
    "        ticks=\"outside\",\n",
    "        row=1,\n",
    "        col=i + 1,\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    # xaxis_title=grouping,\n",
    "    font=dict(\n",
    "        size=16,\n",
    "    ),\n",
    "    # show legend\n",
    "    showlegend=True,\n",
    "    height=700,\n",
    "    width=2000,\n",
    ")\n",
    "\n",
    "fig.update_traces(boxpoints=\"all\", jitter=0.1)\n",
    "\n",
    "fig.update_xaxes(\n",
    "    categoryorder=\"array\",\n",
    "    categoryarray=data.sort_values([\"batch\"])[grouping].unique(),\n",
    ")  #\n",
    "\n",
    "fig.show(renderer=\"browser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513 runs found\n",
      "513 valid runs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/vd6ll12160n19dfsmnsbc1rnhgdmtf/T/ipykernel_27850/3252466185.py:30: DeprecationWarning:\n",
      "\n",
      "In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common columns between cycle_metrics_df and run_info_df: {'run_id'}\n",
      "merging on common cols: ['run_id']\n",
      "MLB000AQ-PS00-01 66\n",
      "MLB003AA-PS00-01 43\n",
      "MLB003AC-PS00-04 33\n",
      "MLB003AC-PS00-03 47\n",
      "MLB003AD-PS00-03 8\n"
     ]
    }
   ],
   "source": [
    "# Query and Plot Reliability\n",
    "# ====================================================================================\n",
    "# ======================        Reliability        =====================================\n",
    "# ====================================================================================\n",
    "\n",
    "\n",
    "# define function for meging dataframes\n",
    "def merge_on_common_cols(df1: pd.DataFrame, df2: pd.DataFrame):\n",
    "    \"\"\"merge on cols in common between two dfs\"\"\"\n",
    "    common_cols = [c for c in df1.columns if c in df2.columns]\n",
    "    print(f\"merging on common cols: {common_cols}\")\n",
    "    return df1.merge(df2, on=common_cols).copy()\n",
    "\n",
    "# set up input variables\n",
    "sample_regix = 'MLD015|MLB003|MLB004'\n",
    "track_cycle_dvdt_cutoff = -1.5E-5\n",
    "charge_cap_fraction_cutoff = 0.849\n",
    "\n",
    "# split sample regex into list\n",
    "sample_prefixes = sample_regix.split(\"|\")\n",
    "\n",
    "test_type = \"E31\"\n",
    "recipe_ids = [15223, 15224, 15263, 15416, 15410, 15287, 15445, 15411, 15529, 15551, 15707, 15756, 15799 ]\n",
    "\n",
    "## Fetch Data\n",
    "# # get meta data about runs for a specific sample prefix and test type\n",
    "run_info_df = qs_client.get_run_info(sample_prefixes=sample_prefixes, test_type=test_type, recipe_ids=recipe_ids)\n",
    "print(f\"{len(run_info_df)} runs found\")\n",
    "\n",
    "run_info_df.loc[:, \"run_id\"] = run_info_df[\"run_id\"].apply(lambda r: int(r))\n",
    "print(f\"{len(run_info_df)} valid runs found\")\n",
    "run_ids = [int(x) for x in run_info_df['run_id']]\n",
    "\n",
    "# # # # # add new columns, miscellaneous\n",
    "run_info_df.loc[:, \"Process Name\"] = run_info_df[\"batch_name\"].apply(lambda s: s[:8])\n",
    "\n",
    "# # # # # drop null columns\n",
    "run_info_df = run_info_df.dropna(axis=0, how=\"all\")\n",
    "\n",
    "# # # # # get the cycle metrics for every run id in run_ids\n",
    "# # # # # this step can take many minutes\n",
    "cycle_metrics_df = qs_client.get_et_cycle_metrics(run_ids=run_ids, test_type=\"E31\")\n",
    "\n",
    "# drop columns will null values\n",
    "# cycle_metrics_df.dropna(subset=[\"voltage_post_ceiling_rest_end_linear_dvdt\", \"min_track_cycle_power\", \"voltage_end_floor_rest\", \"min_track_cycle_voltage\"], inplace=True)\n",
    "\n",
    "# add column to flag shorted cycles\n",
    "\n",
    "\n",
    "cycle_metrics_df[\"is_shorted\"] = (\n",
    "    (cycle_metrics_df[\"voltage_post_ceiling_rest_end_linear_dvdt\"].notnull() &\n",
    "     (cycle_metrics_df[\"voltage_post_ceiling_rest_end_linear_dvdt\"] < track_cycle_dvdt_cutoff))\n",
    "    |\n",
    "    (cycle_metrics_df[\"capacity_charge_fraction\"].notnull() &\n",
    "     (cycle_metrics_df[\"capacity_charge_fraction\"] > charge_cap_fraction_cutoff))\n",
    ")\n",
    "\n",
    "\n",
    "cycle_metrics_df.loc[:, \"V_fail_2.45V\"] = cycle_metrics_df[\"min_track_cycle_voltage\"].apply(\n",
    "    lambda vmin: vmin < 2.25 if pd.notnull(vmin) else False\n",
    ")\n",
    "\n",
    "\n",
    "# # add column to calculate max overpotential\n",
    "\n",
    "cycle_metrics_df.loc[:, \"max_overpotential_V\"] = cycle_metrics_df.apply(\n",
    "    lambda row: (row[\"voltage_end_floor_rest\"] - row[\"min_track_cycle_voltage\"])\n",
    "    if pd.notnull(row[\"voltage_end_floor_rest\"]) and pd.notnull(row[\"min_track_cycle_voltage\"])\n",
    "    else None,  # Assign None if any value is NaN\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check common colums between cycle_metrics_df and run_info_df\n",
    "\n",
    "print(f\"common columns between cycle_metrics_df and run_info_df: {set(cycle_metrics_df.columns) & set(run_info_df.columns)}\")\n",
    "\n",
    "\n",
    "\n",
    "# merge cycle metrics and run info\n",
    "\n",
    "merged_e31_cycle_metrics_df = merge_on_common_cols(cycle_metrics_df, run_info_df)\n",
    "\n",
    "all_e31_cycle_metrics_df = merged_e31_cycle_metrics_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "short_corrections ={'MLB000AQ-PS00-01':66,'MLB003AA-PS00-01':43,'MLB003AC-PS00-04':33,'MLB003AC-PS00-03':47,'MLB003AD-PS00-03':8}\n",
    "\n",
    "\n",
    "# loop thropugh short corrections and set is_shorted to False for each samnple_name and cycle\n",
    "for name, cycle in short_corrections.items():\n",
    "    print(name, cycle)\n",
    "    all_e31_cycle_metrics_df.loc[((all_e31_cycle_metrics_df.sample_name.str.contains(name)) & (all_e31_cycle_metrics_df.track_cycle_count_cumulative==cycle)), \"is_shorted\"] = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Vmin and Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpg01/.pyenv/versions/3.9.10/lib/python3.9/site-packages/lifelines/utils/__init__.py:320: IntegrationWarning:\n",
      "\n",
      "The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inputs for plotting\n",
    "\n",
    "grouping = \"Condition\"\n",
    "samples_to_include = \"MLD015|MLB003|MLB004\"\n",
    "tiers_to_include = [\"Tier 1\", \"Tier 2\"]\n",
    "\n",
    "\n",
    "\n",
    "## Plot Vmin vs Cycle Count\n",
    "plotly_colors = [\n",
    "    # 'rgb(99, 110, 250)',    # Blue\n",
    "    'rgb(239, 85, 59)',     # Red-orange\n",
    "    'rgb(0, 204, 150)',     # Green\n",
    "    'rgb(171, 99, 250)',    # Purple\n",
    "    'rgb(255, 161, 90)',    # Orange\n",
    "    'rgb(25, 211, 243)',    # Cyan\n",
    "    'rgb(255, 102, 146)',   # Pink\n",
    "    'rgb(182, 232, 128)',   # Light green\n",
    "    'rgb(255, 151, 255)',   # Light pink\n",
    "    'rgb(254, 203, 82)'     # Yellow-orange\n",
    "]\n",
    "# //Define a modern pastel color list\n",
    "\n",
    "color_list=plotly_colors\n",
    "\n",
    "df_rel_master_voltage = all_e31_cycle_metrics_df.copy()\n",
    "\n",
    "# change the column name to samplename\n",
    "df_rel_master_voltage.rename(columns={'sample_name': 'samplename'}, inplace=True)\n",
    "\n",
    "# add column for experiment, process, and batch\n",
    "df_rel_master_voltage['experiment'] = df_rel_master_voltage['samplename'].str[0:6]\n",
    "df_rel_master_voltage['process'] = df_rel_master_voltage['samplename'].str[0:8]\n",
    "df_rel_master_voltage['batch'] = df_rel_master_voltage['samplename'].str[0:13]\n",
    "\n",
    "\n",
    "df_rel_master_voltage.loc[df_rel_master_voltage.samplename.str.contains('MLB003'), 'Condition'] = 'C/20 cut current'    \n",
    "df_rel_master_voltage.loc[df_rel_master_voltage.samplename.str.contains('MLB004'), 'Condition'] = 'C/5 cut current' \n",
    "df_rel_master_voltage.loc[df_rel_master_voltage.samplename.str.contains('MLD015'), 'Condition'] = 'C/5 cut current'\n",
    "\n",
    "\n",
    "# cell tier and work week info\n",
    "df_date_ww = df_master[['samplename', 'cell_build_WW', 'cell_tier_group']]\n",
    "df_rel_master_voltage = df_rel_master_voltage.merge(df_date_ww, left_on='samplename', right_on='samplename', how='left')\n",
    "\n",
    "# filter data to desired tier and samples\n",
    "df_rel_master_voltage = df_rel_master_voltage[df_rel_master_voltage['cell_tier_group'].isin(tiers_to_include)]\n",
    "df_rel_master_voltage = df_rel_master_voltage[df_rel_master_voltage['samplename'].str.contains(samples_to_include)]\n",
    "\n",
    "\n",
    "\n",
    "# create dictionary mapping group_by_col to colors\n",
    "color_dict = {}\n",
    "for group in df_rel_master_voltage.groupby(grouping):\n",
    "    if group[0] not in color_dict.keys():\n",
    "        color_dict[group[0]] = {}\n",
    "    color_dict[group[0]] = (color_list)[len(color_dict.keys())-1]\n",
    "\n",
    "\n",
    "# create dictionary mapping samplenames to colors with the same color for each sample in group_by_col\n",
    "sample_color_dict = {}\n",
    "for group in df_rel_master_voltage.groupby(grouping):\n",
    "    for sample in group[1]['samplename'].unique():\n",
    "        if sample not in sample_color_dict.keys():\n",
    "            sample_color_dict[sample] = {}\n",
    "        sample_color_dict[sample] = color_dict[group[0]]\n",
    "\n",
    "# plot min vs count in plotly \n",
    "\n",
    "fig = px.scatter(df_rel_master_voltage, x=\"track_cycle_count_cumulative\", y=\"min_track_cycle_voltage\", color='samplename', title='Min Discharge Voltage vs Track Cycle Count', hover_name='samplename',\n",
    "                 color_discrete_map=sample_color_dict\n",
    ")\n",
    "\n",
    "# Sort the traces in alphabetical order by 'samplename'\n",
    "sorted_samplenames = sorted(df_rel_master_voltage['samplename'].unique())  # Get unique sample names and sort them alphabetically\n",
    "fig.for_each_trace(lambda trace: trace.update(legendgroup=sorted_samplenames.index(trace.name),\n",
    "                                              legendrank=sorted_samplenames.index(trace.name)))\n",
    "\n",
    "fig.update_yaxes(range=[2.2, 3.0], title='Voltage (V)', tickfont=dict(size=22), \n",
    "                # dtick=0.5,\n",
    "                    titlefont=dict(size=22), mirror=True, ticks='outside', showline=True, linewidth=2, linecolor='grey')    \n",
    "\n",
    "fig.update_xaxes(range=[0, 100], title='Cycle Number', tickfont=dict(size=22), \n",
    "                # dtick=0.5,\n",
    "                    titlefont=dict(size=22), mirror=True, ticks='outside', showline=True, linewidth=2, linecolor='grey')  \n",
    "\n",
    "# add markers and lines\n",
    "fig.update_traces(mode='markers+lines', marker=dict(size=10), line=dict(width=2))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=700,\n",
    "    font = dict(size = 20),\n",
    "    plot_bgcolor='white',\n",
    ")\n",
    "\n",
    "# add dotted line at 2.45V\n",
    "fig.add_shape(type=\"line\",\n",
    "    x0=-5, y0=2.45, x1=100, y1=2.45,\n",
    "    line=dict(color=\"black\",width=2, dash=\"dot\")\n",
    ")\n",
    "#fig.show()\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ Plot Track Cycle Reliability\n",
    "\n",
    "\n",
    "Vmin_cut = 'V_fail_2.45V'\n",
    "Vmin_cut_any = 'V_fail_2.45V'\n",
    "\n",
    "\n",
    "df_Vmin = df_rel_master_voltage.merge(\n",
    "    df_rel_master_voltage[[\"samplename\", Vmin_cut]].groupby(\"samplename\").max(),\n",
    "    suffixes=[\"\", \"_any\"],\n",
    "    right_index=True,\n",
    "    left_on=\"samplename\",\n",
    ")\n",
    "\n",
    "v_fail_screen=pd.concat([\n",
    "    df_Vmin.loc[(df_Vmin[Vmin_cut]==True) & (df_Vmin[Vmin_cut_any]==True) ].groupby('samplename').first(),\n",
    "    df_Vmin.loc[(df_Vmin[Vmin_cut]==False) & (df_Vmin[Vmin_cut_any]==False)].groupby('samplename').last()]\n",
    ")\n",
    "\n",
    "\n",
    "v_fail_screen=v_fail_screen[['track_cycle_count_cumulative', Vmin_cut]].reset_index()\n",
    "v_fail_screen=v_fail_screen.rename(columns={'track_cycle_count_cumulative': 'V_Fail_Cycle'})\n",
    "\n",
    "df_rel_master_voltage = pd.merge(df_rel_master_voltage, v_fail_screen, on=['samplename',Vmin_cut], how='left')\n",
    "\n",
    "annotate = True\n",
    "six_layer = False\n",
    "RMST_duration=60\n",
    "\n",
    "\n",
    "width=1200\n",
    "height=800\n",
    "range_x=100\n",
    "\n",
    "\n",
    "df_rel_master_voltage = df_rel_master_voltage.merge(\n",
    "    df_rel_master_voltage[[\"samplename\", \"is_shorted\"]].groupby(\"samplename\").max(),\n",
    "    suffixes=[\"\", \"_any\"],\n",
    "    right_index=True,\n",
    "    left_on=\"samplename\",\n",
    ")\n",
    "\n",
    "df_rel_master_voltage['Fail_Event'] = False\n",
    "\n",
    "df_rel_master_voltage[\"ShortEvent\"] = df_rel_master_voltage['is_shorted']     #change to \"is_shorted_any\"\n",
    "df_rel_master_voltage['EventCycle'] = df_rel_master_voltage['track_cycle_count_cumulative']\n",
    "\n",
    "#label builds that survived\n",
    "df_rel_master_voltage.loc[(df_rel_master_voltage['is_shorted_any'] == False), 'Failure_Type' ]='Survived'#change to \"is_shorted_any\"\n",
    "\n",
    "#label builds that failed via shorting\n",
    "df_rel_master_voltage.loc[(df_rel_master_voltage['is_shorted_any'] == True), 'Fail_Event' ]=True#change to \"is_shorted_any\"\n",
    "df_rel_master_voltage.loc[(df_rel_master_voltage['is_shorted_any'] == True), 'Failure_Type' ]='Short Failure'#change to \"is_shorted_any\"\n",
    "\n",
    "# label builds that failed via Vmin \n",
    "df_rel_master_voltage.loc[((df_rel_master_voltage[Vmin_cut]==True)) , \"Fail_Event\"]=True\n",
    "df_rel_master_voltage.loc[((df_rel_master_voltage[Vmin_cut]==True) & (df_rel_master_voltage['V_Fail_Cycle'] < df_rel_master_voltage['EventCycle'])) , [\"Fail_Event\", \"Failure_Type\" ]]=[True, 'Vmin Failure']\n",
    "df_rel_master_voltage.loc[df_rel_master_voltage[Vmin_cut]==True, 'EventCycle'] = df_rel_master_voltage['V_Fail_Cycle']\n",
    "\n",
    "\n",
    "df_rel_master_voltage_summary=df_rel_master_voltage[['samplename', 'EventCycle', 'Fail_Event', 'Failure_Type','run_end_time', 'recipe_id', 'recipe_name', 'tool_name', 'channel', 'capacity_charge_fraction', grouping]].copy()\n",
    "df_rel_master_voltage_summary = df_rel_master_voltage_summary.drop_duplicates(['samplename'], keep = 'last')\n",
    "\n",
    "\n",
    "## make survival plot\n",
    "fig = make_subplots()\n",
    "fill_color_list=['rgba'+ a[3:-1]+', 0.06)' for a in color_list]\n",
    "i=0\n",
    "\n",
    "kmf1 = KaplanMeierFitter(alpha=0.05)  # this alpha is the Type I error rate\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Condition', 'RMST', 'Variance', '95_CI'])\n",
    "\n",
    "#df_combined_forcsv.to_csv('dvdt_EventCycle_240222.csv')\n",
    "\n",
    "for Batch, grouped in df_rel_master_voltage_summary.groupby(grouping):\n",
    "    \n",
    "    kmf1.fit(durations=grouped[\"EventCycle\"], event_observed=grouped[\"Fail_Event\"])\n",
    "    df = kmf1.survival_function_.join(kmf1.confidence_interval_survival_function_)\n",
    "    df = df.join(\n",
    "        grouped.set_index(\"samplename\")[[\"EventCycle\", \"Fail_Event\", \"Failure_Type\"]]\n",
    "        .reset_index()\n",
    "        .groupby([\"EventCycle\", \"Fail_Event\", \"Failure_Type\"])\n",
    "        .agg({\"samplename\": \"<br>\\n\".join})\n",
    "        .reset_index()\n",
    "        .set_index(\"EventCycle\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    df = df.fillna(value=True)\n",
    "    df[\"Fail_Event\"] = df[\"Fail_Event\"].apply(int)\n",
    "    df.loc[df.index==0, \"Fail_Event\" ] = 0\n",
    "    df['color']=color_list[i]\n",
    "\n",
    "    df['Fail_Short']=0\n",
    "    df.loc[df['Failure_Type']=='Short', 'Fail_Short']=1\n",
    "    df.loc[df['Failure_Type']=='Voltage', 'color']='yellow'\n",
    "\n",
    "    # Calculate RMST and variance\n",
    "    rmst, variance = restricted_mean_survival_time(kmf1, t=RMST_duration, return_variance=True)\n",
    "    \n",
    "    standard_error = np.sqrt(variance)\n",
    "    z_score = 1.96  # for 95% confidence interval\n",
    "\n",
    "    # Compute confidence intervals\n",
    "    ci = z_score * standard_error\n",
    "    \n",
    "\n",
    "    # Append results to the DataFrame\n",
    "    results_df = results_df.append({'Condition': Batch,\n",
    "                                    'RMST': rmst,\n",
    "                                    'Variance': variance,\n",
    "                                    '95_CI': ci}, ignore_index=True)\n",
    "    \n",
    "\n",
    "    if six_layer:\n",
    "        if '6L' not in Batch:\n",
    "            df['KM_estimate']=df['KM_estimate']**3\n",
    "            df['KM_estimate_lower_0.95']=df['KM_estimate_lower_0.95']**3\n",
    "            df['KM_estimate_upper_0.95']=df['KM_estimate_upper_0.95']**3\n",
    "\n",
    "\n",
    "    trace1 = {\n",
    "        \"x\": df.index,\n",
    "        \"y\": df.KM_estimate,\n",
    "        \"line\": {\"shape\": \"hv\"},\n",
    "        \"mode\": \"lines\",\n",
    "        \"name\": \"value\",\n",
    "        \"type\": \"scatter\",\n",
    "    }\n",
    "\n",
    "    df=df.dropna(subset='Fail_Event')\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=df.KM_estimate * 100,\n",
    "            mode=\"markers+lines\",\n",
    "            line=dict(shape=\"hv\", width=3, color=color_list[i]),\n",
    "            marker=dict(color=df['color'], symbol='circle', size=7*(1-df['Fail_Short'])),\n",
    "            hovertext=df.samplename,\n",
    "            name=f\"{Batch} (N={len(grouped)})\",\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=df[\"KM_estimate_upper_0.95\"] * 100,\n",
    "            mode=\"lines\",\n",
    "            line=dict(shape=\"hv\", width=0, color=color_list[i]),\n",
    "            name=\"\",  # f\"{Batch} UCI95%\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=df[\"KM_estimate_lower_0.95\"] * 100,\n",
    "            mode=\"lines\",\n",
    "            fill=\"tonexty\",\n",
    "            fillcolor=fill_color_list[i],\n",
    "            line=dict(shape=\"hv\", width=0, color=color_list[i]),\n",
    "            name=\"\",  # f\"{Batch} LCI95%\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Reliability Test\",\n",
    "    xaxis=dict(title=\"Cycle Number\"),\n",
    "    yaxis=dict(title=\"Survival (%)\"),\n",
    "    font=dict(size=20),\n",
    "    legend={\"traceorder\": \"normal\"},\n",
    "    legend_title_text=grouping,\n",
    "    # autosize=False,S\n",
    "    width=1050,\n",
    "    height=600,\n",
    "    # hide the legend\n",
    "    # showlegend=False,\n",
    ")\n",
    "\n",
    "# set background color to white\n",
    "fig.update_layout(plot_bgcolor='white')\n",
    "fig.update_yaxes(range=[0, 105], showline=True, linewidth=1, linecolor=\"black\", mirror=True)\n",
    "fig.update_xaxes(range=[0, 100], showline=True, linewidth=1, linecolor=\"black\", mirror=True)\n",
    "\n",
    "\n",
    "if annotate:\n",
    "# add vertical grey dashed line to figure at 60 cycles\n",
    "    fig.add_shape(\n",
    "            # Line Vertical\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                x0=60,\n",
    "                y0=0,\n",
    "                x1=60,\n",
    "                y1=105,\n",
    "                line=dict(\n",
    "                    color=\"Grey\",\n",
    "                    width=3,\n",
    "                    dash=\"dash\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[10],\n",
    "        y=[94],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=\"red\", symbol=\"circle\", size=20),\n",
    "        hovertext='95% Survival',\n",
    "        name=\"\",\n",
    "        # remove from legend\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    secondary_y=False,\n",
    "    )\n",
    "\n",
    "# add red circle at 60 cycles and 50% survival\n",
    "\n",
    "    # fig.add_trace(\n",
    "    #     go.Scatter(\n",
    "    #         x=[60],\n",
    "    #         y=[88],\n",
    "    #         mode=\"markers\",\n",
    "    #         marker=dict(color=\"red\", symbol=\"circle\", size=20),\n",
    "    #         hovertext='50% Survival',\n",
    "    #         name=\"\",\n",
    "    #         # remove from legend\n",
    "    #         showlegend=False,\n",
    "    #     ),\n",
    "    #     secondary_y=False,\n",
    "    # )\n",
    "\n",
    "fig.update_yaxes(range=[0, 105])\n",
    "fig.update_xaxes(range=[0, range_x])\n",
    "\n",
    "fig.show(renderer=\"browser\")\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce ML Summary Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce ML Summary Spreadsheet\n",
    "# ====================================================================================\n",
    "# ====================  Yield and Reliability Summary   ==============================\n",
    "# ====================================================================================\n",
    "\n",
    "#Step 1: Create dataframes that summarizes ML Screen and Reliability Performances\n",
    "#bring up summary of screen data\n",
    "df_screening = df_master[['samplename', 'cell_tier_group', 'Yield Count', '1C Count', 'Fast-Charge Count', 'C/3 Count', 'cell_build_date', 'Tool', 'Channel']]\n",
    "df_screening.rename(columns={\"Yield Count\": \"ML Screen\"}, inplace=True)\n",
    "df_screening['ML Screen'] = df_screening['ML Screen'].replace({1: 'Pass', 0: 'Fail'})\n",
    "df_failed = df_master[(df_master[\"C/3 Count\"] == 0)][['samplename', \"1C Count\", \"Fast-Charge Count\", 'C/3 Count', 'cell_tier_group', 'cell_build_date', 'Tool', 'Channel']]\n",
    "df_passed = df_master[(df_master[\"C/3 Count\"] == 1)][['samplename', \"1C Count\", \"Fast-Charge Count\", 'C/3 Count', 'cell_tier_group', 'cell_build_date', 'Tool', 'Channel']]\n",
    "#bring up summary of reliability data\n",
    "rel_summary = df_rel_master_voltage_summary.copy()\n",
    "\n",
    "# Step 2: Merge screen and reliability dataframes\n",
    "df_screening = df_screening.merge(rel_summary, on='samplename', how='left')\n",
    "df_screening['Fail_Event'] = df_screening['Fail_Event'].replace({False: 'Pass', True: 'Failed'})\n",
    "df_screening = df_screening.rename(columns={'Fail_Event': 'Reliability Result'})\n",
    "df_screening = df_screening.rename(columns={'EventCycle': 'Total Reliability Cycles'})\n",
    "df_screening = df_screening.rename(columns={\"run_end_time\": \"Last Reliability Cycle\"})\n",
    "df_screening['Last Reliability Cycle'] = df_screening['Last Reliability Cycle'].str[:10]\n",
    "\n",
    "# Step 3: Update \"Reliability Result\" based on conditions\n",
    "today = datetime.today().date()\n",
    "df_screening['Last Reliability Cycle'] = pd.to_datetime(df_screening['Last Reliability Cycle'], errors='coerce')\n",
    "#Input Failiure mode to  `Reliability Result`\n",
    "df_screening['Reliability Result'] = np.where(\n",
    "    df_screening['Reliability Result'] == 'Failed', \n",
    "    df_screening['Failure_Type'], \n",
    "    df_screening['Reliability Result']\n",
    ")\n",
    "#Update status if it has not failed\n",
    "df_screening['Reliability Result'] = np.where(\n",
    "    (df_screening['Reliability Result'] == 'Pass') & \n",
    "    ((df_screening['Last Reliability Cycle'].dt.date == today) | df_screening['Last Reliability Cycle'].isna()),\n",
    "    'In-Progress',\n",
    "    np.where(\n",
    "        (df_screening['Reliability Result'] == 'Pass') & \n",
    "        (df_screening['Last Reliability Cycle'].dt.date != today),\n",
    "        'Stopped/Finished',\n",
    "        df_screening['Reliability Result']\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "#Step 4: Add Disposition\n",
    "# Define the conditions for the \"Disposition\" column\n",
    "conditions = [\n",
    "    (df_screening['Reliability Result'] == 'In-Progress'),\n",
    "    (df_screening['Reliability Result'] == 'Stopped/Finished'),\n",
    "    (df_screening['Reliability Result'].isin(['Vmin Failure', 'Short Failure'])),\n",
    "    (df_screening['C/3 Count'] == 0) & (df_screening['ML Screen'] == 'Pass')\n",
    "]\n",
    "# Define the corresponding values for each condition\n",
    "choices = [\n",
    "    'Still Cycling',\n",
    "    'Finished Cycling',\n",
    "    'Failed Cycling',\n",
    "    'Still Screening'\n",
    "]\n",
    "# Apply the conditions to create the \"Disposition\" column\n",
    "df_screening['Disposition'] = np.select(conditions, choices, default='Finished Screening')\n",
    "# Insert \"Disposition\" as the second column\n",
    "cols = df_screening.columns.tolist()  # Get the current column order\n",
    "cols.insert(1, cols.pop(cols.index('Disposition')))  # Move \"Disposition\" to the second position\n",
    "df_screening = df_screening[cols]  # Reorder columns\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Update Maccor and Channel if cell is in reliability testing\n",
    "df_updated = df_screening.merge(\n",
    "    df_rel_master_voltage_summary[['samplename', 'tool_name', 'channel']],\n",
    "    on='samplename',\n",
    "    how='left',\n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "df_updated['Tool'] = df_updated['tool_name'].combine_first(df_updated['Tool'])\n",
    "df_updated['Channel'] = df_updated['channel'].combine_first(df_updated['Channel'])\n",
    "df_updated = df_updated.drop(columns=['tool_name', 'channel'])\n",
    "\n",
    "\n",
    "# Step 6: Sort by 'cell_build_date' first, and then by 'samplename'\n",
    "df_screening = df_updated.sort_values(by=['cell_build_date', 'samplename'], ascending=[True, True])\n",
    "#clean up and remove columns from dataframe\n",
    "df_screening = df_screening[['samplename','Disposition', 'cell_tier_group', 'cell_build_date', 'Tool', 'Channel', 'ML Screen', 'Reliability Result', 'Total Reliability Cycles','Last Reliability Cycle', 'recipe_name']]\n",
    "\n",
    "\n",
    "# Step 7: Save the updated dataframe\n",
    "Output_name = 'ML_TrackingResults.xlsx'\n",
    "df_screening.to_excel(Output_name, index=False)\n",
    "#df_screening.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ML Screen Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_master.copy()\n",
    "\n",
    "\n",
    "data = data[data[\"C/3 Count\"] == 1]\n",
    "\n",
    "\n",
    "data = data[data.samplename.str.contains('QSC022')]\n",
    "\n",
    "data.loc[data.samplename.str.contains('QSC022'), 'Condition'] = '6L Candidates'\n",
    "data.loc[data.samplename.str.contains('QSC022AE-PS00-0[1,2,3]|QSC022AF-PS00-02|QSC022AH-PS00-02|QSC022AD-PS00-01'), 'Condition'] = 'Top 6 TOPSIS'\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Columns you want to plot\n",
    "columns_to_plot = [\n",
    "       'AMSDischargeCapactiy_1C', \n",
    "    #    'DischargeCapactiy_1C',\n",
    "       'AMSDischargeCapactiy_Co3', \n",
    "       'DischargeCapactiy_Co3',\n",
    "       'MedDischargeASR_1C', \n",
    "       'MedDischargeASR_1C_delta', \n",
    "    #    'dVdt_delta_1C',\n",
    "       'dVdt_delta_fastcharge', \n",
    "    #    'dVdt_1C', \n",
    "      #  'CE_1C'\n",
    "       \n",
    "       ]\n",
    "\n",
    "\n",
    "data.loc[data.samplename.str.contains('QSC022AE-PS00-02'), 'MedDischargeASR_1C_delta'] = 0.26\n",
    "\n",
    "# Colors for the boxplots, you can adjust this as needed\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=columns_to_plot)\n",
    "\n",
    "# Loop through the columns and add a boxplot to each subplot\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    fig.add_trace(\n",
    "        go.Box(x=data['Condition'],y=data[column], name=column, marker_color=colors[i % len(colors)], \n",
    "               boxpoints='all',  # Show all points\n",
    "               jitter=0.3,  # Spread out points for better visibility\n",
    "               pointpos=-1.5,  # Position points symmetrically around the center\n",
    "               hoverinfo='y+text',  # Customize hover information\n",
    "               text=data['samplename'],  # This will set hover text to the 'samplename' column  # Show only the y-axis value when hovering\n",
    "               showlegend=False),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    # Update the y-axis title for each subplot\n",
    "    fig.update_yaxes(title_text=column, tickfont=dict(size=16), titlefont=dict(size=16),\n",
    "                     mirror=True, ticks='outside', showline=True, linewidth=2, linecolor='grey', title_standoff=5,\n",
    "                     row=row, col=col)\n",
    "    fig.update_xaxes(categoryorder='array', categoryarray=['Validation', 'Shippment<br>Candidates<br>Tier 1a', 'Shippment<br>Candidates<br>Tier 1b'])\n",
    "\n",
    "# Update x axes titles\n",
    "fig.update_xaxes(title_text='', tickfont=dict(size=16),\n",
    "                 titlefont=dict(size=16), mirror=True, ticks='outside', showline=True, \n",
    "                 linewidth=2, linecolor='grey')\n",
    "\n",
    "# Adjust layout\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    yaxis=dict(showgrid=True, gridcolor='lightgrey'),\n",
    "    autosize=False,\n",
    "    width=1100,\n",
    "    height=800,\n",
    "    font=dict(size=20),\n",
    "    title='Boxplots for Multiple Metrics'\n",
    ")\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
